

<!DOCTYPE html>


<html lang="en" data-content_root="" >

  <head>
    <meta charset="utf-8" />
    <meta name="viewport" content="width=device-width, initial-scale=1.0" /><meta name="generator" content="Docutils 0.18.1: http://docutils.sourceforge.net/" />

    <title>3.1. Chunking &#8212; AI Workshop</title>
  
  
  
  <script data-cfasync="false">
    document.documentElement.dataset.mode = localStorage.getItem("mode") || "";
    document.documentElement.dataset.theme = localStorage.getItem("theme") || "light";
  </script>
  
  <!-- Loaded before other Sphinx assets -->
  <link href="_static/styles/theme.css?digest=8d27b9dea8ad943066ae" rel="stylesheet" />
<link href="_static/styles/bootstrap.css?digest=8d27b9dea8ad943066ae" rel="stylesheet" />
<link href="_static/styles/pydata-sphinx-theme.css?digest=8d27b9dea8ad943066ae" rel="stylesheet" />

  
  <link href="_static/vendor/fontawesome/6.5.1/css/all.min.css?digest=8d27b9dea8ad943066ae" rel="stylesheet" />
  <link rel="preload" as="font" type="font/woff2" crossorigin href="_static/vendor/fontawesome/6.5.1/webfonts/fa-solid-900.woff2" />
<link rel="preload" as="font" type="font/woff2" crossorigin href="_static/vendor/fontawesome/6.5.1/webfonts/fa-brands-400.woff2" />
<link rel="preload" as="font" type="font/woff2" crossorigin href="_static/vendor/fontawesome/6.5.1/webfonts/fa-regular-400.woff2" />

    <link rel="stylesheet" type="text/css" href="_static/pygments.css" />
    <link rel="stylesheet" href="_static/styles/sphinx-book-theme.css?digest=14f4ca6b54d191a8c7657f6c759bf11a5fb86285" type="text/css" />
    <link rel="stylesheet" type="text/css" href="_static/togglebutton.css" />
    <link rel="stylesheet" type="text/css" href="_static/copybutton.css" />
    <link rel="stylesheet" type="text/css" href="_static/mystnb.4510f1fc1dee50b3e5859aac5469c37c29e427902b24a333a5f9fcb2f0b3ac41.css" />
    <link rel="stylesheet" type="text/css" href="_static/sphinx-thebe.css" />
    <link rel="stylesheet" type="text/css" href="_static/design-style.4045f2051d55cab465a707391d5b2007.min.css" />
  
  <!-- Pre-loaded scripts that we'll load fully later -->
  <link rel="preload" as="script" href="_static/scripts/bootstrap.js?digest=8d27b9dea8ad943066ae" />
<link rel="preload" as="script" href="_static/scripts/pydata-sphinx-theme.js?digest=8d27b9dea8ad943066ae" />
  <script src="_static/vendor/fontawesome/6.5.1/js/all.min.js?digest=8d27b9dea8ad943066ae"></script>

    <script data-url_root="./" id="documentation_options" src="_static/documentation_options.js"></script>
    <script src="_static/jquery.js"></script>
    <script src="_static/underscore.js"></script>
    <script src="_static/_sphinx_javascript_frameworks_compat.js"></script>
    <script src="_static/doctools.js"></script>
    <script src="_static/clipboard.min.js"></script>
    <script src="_static/copybutton.js"></script>
    <script src="_static/scripts/sphinx-book-theme.js?digest=5a5c038af52cf7bc1a1ec88eea08e6366ee68824"></script>
    <script>let toggleHintShow = 'Click to show';</script>
    <script>let toggleHintHide = 'Click to hide';</script>
    <script>let toggleOpenOnPrint = 'true';</script>
    <script src="_static/togglebutton.js"></script>
    <script>var togglebuttonSelector = '.toggle, .admonition.dropdown';</script>
    <script src="_static/design-tabs.js"></script>
    <script>const THEBE_JS_URL = "https://unpkg.com/thebe@0.8.2/lib/index.js"
const thebe_selector = ".thebe,.cell"
const thebe_selector_input = "pre"
const thebe_selector_output = ".output, .cell_output"
</script>
    <script async="async" src="_static/sphinx-thebe.js"></script>
    <script>DOCUMENTATION_OPTIONS.pagename = '3.1.experiment_chunking';</script>
    <link rel="index" title="Index" href="genindex.html" />
    <link rel="search" title="Search" href="search.html" />
    <link rel="next" title="3.2. Embeddings" href="3.2.experiment_embedding.html" />
    <link rel="prev" title="3. Experiments" href="3.experiment.html" />
  <meta name="viewport" content="width=device-width, initial-scale=1"/>
  <meta name="docsearch:language" content="en"/>
  </head>
  
  
  <body data-bs-spy="scroll" data-bs-target=".bd-toc-nav" data-offset="180" data-bs-root-margin="0px 0px -60%" data-default-mode="">

  
  
  <a id="pst-skip-link" class="skip-link" href="#main-content">Skip to main content</a>
  
  <div id="pst-scroll-pixel-helper"></div>
  
  <button type="button" class="btn rounded-pill" id="pst-back-to-top">
    <i class="fa-solid fa-arrow-up"></i>
    Back to top
  </button>

  
  <input type="checkbox"
          class="sidebar-toggle"
          name="__primary"
          id="__primary"/>
  <label class="overlay overlay-primary" for="__primary"></label>
  
  <input type="checkbox"
          class="sidebar-toggle"
          name="__secondary"
          id="__secondary"/>
  <label class="overlay overlay-secondary" for="__secondary"></label>
  
  <div class="search-button__wrapper">
    <div class="search-button__overlay"></div>
    <div class="search-button__search-container">
<form class="bd-search d-flex align-items-center"
      action="search.html"
      method="get">
  <i class="fa-solid fa-magnifying-glass"></i>
  <input type="search"
         class="form-control"
         name="q"
         id="search-input"
         placeholder="Search this book..."
         aria-label="Search this book..."
         autocomplete="off"
         autocorrect="off"
         autocapitalize="off"
         spellcheck="false"/>
  <span class="search-button__kbd-shortcut"><kbd class="kbd-shortcut__modifier">Ctrl</kbd>+<kbd>K</kbd></span>
</form></div>
  </div>
  
    <header class="bd-header navbar navbar-expand-lg bd-navbar">
    </header>
  

  <div class="bd-container">
    <div class="bd-container__inner bd-page-width">
      
      
      
      <div class="bd-sidebar-primary bd-sidebar">
        

  
  <div class="sidebar-header-items sidebar-primary__section">
    
    
    
    
  </div>
  
    <div class="sidebar-primary-items__start sidebar-primary__section">
        <div class="sidebar-primary-item">

  

<a class="navbar-brand logo" href="0.intro.html">
  
  
  
  
  
    
    
      
    
    
    <img src="_static/logo.png" class="logo__image only-light" alt="AI Workshop - Home"/>
    <script>document.write(`<img src="_static/logo.png" class="logo__image only-dark" alt="AI Workshop - Home"/>`);</script>
  
  
</a></div>
        <div class="sidebar-primary-item"><nav class="bd-links" id="bd-docs-nav" aria-label="Main">
    <div class="bd-toc-item navbar-nav active">
        
        <ul class="nav bd-sidenav bd-sidenav__home-link">
            <li class="toctree-l1">
                <a class="reference internal" href="0.intro.html">
                    Welcome
                </a>
            </li>
        </ul>
        <ul class="current nav bd-sidenav">
<li class="toctree-l1"><a class="reference internal" href="1.rag-intro.html">1. Retrieval Augmented Generation</a></li>
<li class="toctree-l1"><a class="reference internal" href="2.rag-implementation.html">Workshop Setup</a></li>
<li class="toctree-l1"><a class="reference internal" href="2.rag-implementation_integrated.html">Workshop Setup</a></li>



<li class="toctree-l1"><a class="reference internal" href="3.experiment.html">3. Experiments</a></li>
<li class="toctree-l1 current active"><a class="current reference internal" href="#">3.1. Chunking</a></li>
<li class="toctree-l1"><a class="reference internal" href="3.2.experiment_embedding.html">3.2. Embeddings</a></li>
<li class="toctree-l1"><a class="reference internal" href="10.evaluation-production.html">Post-production</a></li>
</ul>

    </div>
</nav></div>
    </div>
  
  
  <div class="sidebar-primary-items__end sidebar-primary__section">
  </div>
  
  <div id="rtd-footer-container"></div>


      </div>
      
      <main id="main-content" class="bd-main">
        
        

<div class="sbt-scroll-pixel-helper"></div>

          <div class="bd-content">
            <div class="bd-article-container">
              
              <div class="bd-header-article">
<div class="header-article-items header-article__inner">
  
    <div class="header-article-items__start">
      
        <div class="header-article-item"><label class="sidebar-toggle primary-toggle btn btn-sm" for="__primary" title="Toggle primary sidebar" data-bs-placement="bottom" data-bs-toggle="tooltip">
  <span class="fa-solid fa-bars"></span>
</label></div>
      
    </div>
  
  
    <div class="header-article-items__end">
      
        <div class="header-article-item">

<div class="article-header-buttons">





<div class="dropdown dropdown-source-buttons">
  <button class="btn dropdown-toggle" type="button" data-bs-toggle="dropdown" aria-expanded="false" aria-label="Source repositories">
    <i class="fab fa-github"></i>
  </button>
  <ul class="dropdown-menu">
      
      
      
      <li><a href="https://github.com/executablebooks/jupyter-book" target="_blank"
   class="btn btn-sm btn-source-repository-button dropdown-item"
   title="Source repository"
   data-bs-placement="left" data-bs-toggle="tooltip"
>
  

<span class="btn__icon-container">
  <i class="fab fa-github"></i>
  </span>
<span class="btn__text-container">Repository</span>
</a>
</li>
      
      
      
      
      <li><a href="https://github.com/executablebooks/jupyter-book/issues/new?title=Issue%20on%20page%20%2F3.1.experiment_chunking.html&body=Your%20issue%20content%20here." target="_blank"
   class="btn btn-sm btn-source-issues-button dropdown-item"
   title="Open an issue"
   data-bs-placement="left" data-bs-toggle="tooltip"
>
  

<span class="btn__icon-container">
  <i class="fas fa-lightbulb"></i>
  </span>
<span class="btn__text-container">Open issue</span>
</a>
</li>
      
  </ul>
</div>






<div class="dropdown dropdown-download-buttons">
  <button class="btn dropdown-toggle" type="button" data-bs-toggle="dropdown" aria-expanded="false" aria-label="Download this page">
    <i class="fas fa-download"></i>
  </button>
  <ul class="dropdown-menu">
      
      
      
      <li><a href="_sources/3.1.experiment_chunking.ipynb" target="_blank"
   class="btn btn-sm btn-download-source-button dropdown-item"
   title="Download source file"
   data-bs-placement="left" data-bs-toggle="tooltip"
>
  

<span class="btn__icon-container">
  <i class="fas fa-file"></i>
  </span>
<span class="btn__text-container">.ipynb</span>
</a>
</li>
      
      
      
      
      <li>
<button onclick="window.print()"
  class="btn btn-sm btn-download-pdf-button dropdown-item"
  title="Print to PDF"
  data-bs-placement="left" data-bs-toggle="tooltip"
>
  

<span class="btn__icon-container">
  <i class="fas fa-file-pdf"></i>
  </span>
<span class="btn__text-container">.pdf</span>
</button>
</li>
      
  </ul>
</div>




<button onclick="toggleFullScreen()"
  class="btn btn-sm btn-fullscreen-button"
  title="Fullscreen mode"
  data-bs-placement="bottom" data-bs-toggle="tooltip"
>
  

<span class="btn__icon-container">
  <i class="fas fa-expand"></i>
  </span>

</button>



<script>
document.write(`
  <button class="btn btn-sm navbar-btn theme-switch-button" title="light/dark" aria-label="light/dark" data-bs-placement="bottom" data-bs-toggle="tooltip">
    <span class="theme-switch nav-link" data-mode="light"><i class="fa-solid fa-sun fa-lg"></i></span>
    <span class="theme-switch nav-link" data-mode="dark"><i class="fa-solid fa-moon fa-lg"></i></span>
    <span class="theme-switch nav-link" data-mode="auto"><i class="fa-solid fa-circle-half-stroke fa-lg"></i></span>
  </button>
`);
</script>


<script>
document.write(`
  <button class="btn btn-sm navbar-btn search-button search-button__button" title="Search" aria-label="Search" data-bs-placement="bottom" data-bs-toggle="tooltip">
    <i class="fa-solid fa-magnifying-glass fa-lg"></i>
  </button>
`);
</script>
<label class="sidebar-toggle secondary-toggle btn btn-sm" for="__secondary"title="Toggle secondary sidebar" data-bs-placement="bottom" data-bs-toggle="tooltip">
    <span class="fa-solid fa-list"></span>
</label>
</div></div>
      
    </div>
  
</div>
</div>
              
              

<div id="jb-print-docs-body" class="onlyprint">
    <h1>3.1. Chunking</h1>
    <!-- Table of contents -->
    <div id="print-main-content">
        <div id="jb-print-toc">
            
            <div>
                <h2> Contents </h2>
            </div>
            <nav aria-label="Page">
                <ul class="visible nav section-nav flex-column">
<li class="toc-h2 nav-item toc-entry"><a class="reference internal nav-link" href="#why-chunking-size-matters">Why Chunking Size Matters</a></li>
</ul>
            </nav>
        </div>
    </div>
</div>

              
                
<div id="searchbox"></div>
                <article class="bd-article">
                  
  <section class="tex2jax_ignore mathjax_ignore" id="chunking">
<h1>3.1. Chunking<a class="headerlink" href="#chunking" title="Permalink to this heading">#</a></h1>
<p>The search solution is comprised of both <strong>ingestion</strong> and <strong>retrieval</strong>. One does not exist without the other.</p>
<p>While the other experiments are focused on data retrieval, ingestion plays equal importance in the effectiveness of the search solution.</p>
<p>Certain aspects of data ingestion need to be experimented as part of the experimentation phase:</p>
<div class="admonition note">
<p class="admonition-title">Note</p>
<p>Other pre and post-processing techniques include: Optical Character Recognition, data conversation, use of Azure Form Recognizer to extract information from the documents, chunking, summarization, post-processing to make data more “human like”, video captioning, speech to text, tagging, etc. are all methods that need to be considered and experimented with as part of the ingestion pipeline experimentation.</p>
</div>
<p><a class="github reference external" href="https://github.com/microsoft/rag-openai/blob/main/topics/RAG_EnablingSearch.md#learnings-from-engagements-1">microsoft/rag-openai</a></p>
<p>When processing data, splitting the source documents into chunks requires care and expertise to ensure the resulting chunks are small enough to be effective during fact retrieval but not too small so that enough context is provided during summarization.</p>
<div class="admonition note">
<p class="admonition-title">Note</p>
<p>Our goal here is not to identify which chunking strategy is the “best” in general but rather to demonstrate how various choices of chunking may have a non-trivial impact on the ultimate outcome from the retrieval-augmented-generation solution.</p>
</div>
<!-- https://vectara.com/blog/grounded-generation-done-right-chunking/#:~:text=In%20the%20context%20of%20Grounded%20Generation%2C%20chunking%20is,find%20natural%20segments%20like%20complete%20sentences%20or%20paragraphs. -->
<section id="why-chunking-size-matters">
<h2>Why Chunking Size Matters<a class="headerlink" href="#why-chunking-size-matters" title="Permalink to this heading">#</a></h2>
<p>As mentioned <a class="reference external" href="https://learn.microsoft.com/en-us/azure/search/semantic-search-overview">here</a>, the models used to generate embedding vectors have maximum limits on the text fragments provided as input. For example, the maximum length of input text for the Azure OpenAI embedding models is <strong>8,191</strong> tokens. Given that each token is around 4 characters of text for common OpenAI models, this maximum limit is equivalent to around 6000 words of text. If you’re using these models to generate embeddings, it’s critical that the input text stays under the limit. Partitioning your content into chunks ensures that your data can be processed by the Large Language Models (LLM) used for indexing and queries.</p>
<p><strong>Relevance and Granularity</strong>: A small chunk size, like 128, yields more granular chunks. This granularity, however, presents a risk: vital information might not be among the top retrieved chunks, especially if the similarity <em>top_k</em> setting is as restrictive as 2. Conversely, a chunk size of 512 is likely to encompass all necessary information within the top chunks, ensuring that answers to queries are readily available. To navigate this, we employ the <em>Faithfulness and Relevancy</em> metrics. These measure the absence of ‘hallucinations’ and the ‘relevancy’ of responses based on the query and the retrieved contexts respectively.</p>
<p><strong>Response Generation Time</strong>: As the chunk_size increases, so does the volume of information directed into the LLM to generate an answer. While this can ensure a more comprehensive context, it might also slow down the system. Ensuring that the added depth doesn’t compromise the system’s responsiveness is crucial.</p>
<p>In essence, determining the optimal chunk_size is about striking a balance: capturing all essential information without sacrificing speed. It’s vital to undergo thorough testing with various sizes to find a configuration that suits the specific use case and dataset.</p>
<p><a class="reference external" href="https://blog.llamaindex.ai/evaluating-the-ideal-chunk-size-for-a-rag-system-using-llamaindex-6207e5d3fec5">https://blog.llamaindex.ai/evaluating-the-ideal-chunk-size-for-a-rag-system-using-llamaindex-6207e5d3fec5</a></p>
<p>Example code: <a class="github reference external" href="https://github.com/Azure/azure-search-vector-samples/blob/main/demo-python/code/data-chunking/textsplit-data-chunking-example.ipynb">Azure/azure-search-vector-samples</a></p>
<p>Read <a class="reference external" href="https://learn.microsoft.com/en-us/azure/search/semantic-search-overview">Common Chunking Technique</a>, <a class="reference external" href="https://learn.microsoft.com/en-us/azure/search/vector-search-how-to-chunk-documents#content-overlap-considerations">Content overlap considerations</a>, <a class="reference external" href="https://learn.microsoft.com/en-us/azure/search/vector-search-how-to-chunk-documents#content-overlap-considerations">Simple example of how to create chunks with sentences</a></p>
<p>CODE: <a class="github reference external" href="https://github.com/microsoft/rag-openai/blob/438999a5470bef7946fa1c8714ed1090e1ed40c3/samples/searchEvaluation/customskills/utils/chunker/text_chunker.py">microsoft/rag-openai</a></p>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="o">%</span><span class="k">pip</span> install langchain-community==0.0.18
<span class="c1"># %pip install langchain-core==0.1.20</span>
<span class="o">%</span><span class="k">pip</span> install unstructured==0.12.3
<span class="o">%</span><span class="k">pip</span> install unstructured-client==0.17.0
<span class="o">%</span><span class="k">pip</span> install langchain==0.1.5
</pre></div>
</div>
</div>
<div class="cell_output docutils container">
<div class="output stream highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>Collecting langchain-community==0.0.18Note: you may need to restart the kernel to use updated packages.

  Using cached langchain_community-0.0.18-py3-none-any.whl.metadata (7.9 kB)
Requirement already satisfied: PyYAML&gt;=5.3 in c:\users\adnegrau\appdata\local\programs\python\python312\lib\site-packages (from langchain-community==0.0.18) (6.0.1)
Requirement already satisfied: SQLAlchemy&lt;3,&gt;=1.4 in c:\users\adnegrau\appdata\local\programs\python\python312\lib\site-packages (from langchain-community==0.0.18) (2.0.25)
Collecting aiohttp&lt;4.0.0,&gt;=3.8.3 (from langchain-community==0.0.18)
  Downloading aiohttp-3.9.3-cp312-cp312-win_amd64.whl.metadata (7.6 kB)
Collecting dataclasses-json&lt;0.7,&gt;=0.5.7 (from langchain-community==0.0.18)
  Using cached dataclasses_json-0.6.4-py3-none-any.whl.metadata (25 kB)
Collecting langchain-core&lt;0.2,&gt;=0.1.19 (from langchain-community==0.0.18)
  Using cached langchain_core-0.1.22-py3-none-any.whl.metadata (6.0 kB)
Collecting langsmith&lt;0.1,&gt;=0.0.83 (from langchain-community==0.0.18)
  Downloading langsmith-0.0.90-py3-none-any.whl.metadata (9.9 kB)
Requirement already satisfied: numpy&lt;2,&gt;=1 in c:\users\adnegrau\appdata\local\programs\python\python312\lib\site-packages (from langchain-community==0.0.18) (1.26.3)
Requirement already satisfied: requests&lt;3,&gt;=2 in c:\users\adnegrau\appdata\local\programs\python\python312\lib\site-packages (from langchain-community==0.0.18) (2.31.0)
Collecting tenacity&lt;9.0.0,&gt;=8.1.0 (from langchain-community==0.0.18)
  Using cached tenacity-8.2.3-py3-none-any.whl.metadata (1.0 kB)
Collecting aiosignal&gt;=1.1.2 (from aiohttp&lt;4.0.0,&gt;=3.8.3-&gt;langchain-community==0.0.18)
  Using cached aiosignal-1.3.1-py3-none-any.whl (7.6 kB)
Requirement already satisfied: attrs&gt;=17.3.0 in c:\users\adnegrau\appdata\local\programs\python\python312\lib\site-packages (from aiohttp&lt;4.0.0,&gt;=3.8.3-&gt;langchain-community==0.0.18) (23.2.0)
Collecting frozenlist&gt;=1.1.1 (from aiohttp&lt;4.0.0,&gt;=3.8.3-&gt;langchain-community==0.0.18)
  Downloading frozenlist-1.4.1-cp312-cp312-win_amd64.whl.metadata (12 kB)
Collecting multidict&lt;7.0,&gt;=4.5 (from aiohttp&lt;4.0.0,&gt;=3.8.3-&gt;langchain-community==0.0.18)
  Downloading multidict-6.0.5-cp312-cp312-win_amd64.whl.metadata (4.3 kB)
Collecting yarl&lt;2.0,&gt;=1.0 (from aiohttp&lt;4.0.0,&gt;=3.8.3-&gt;langchain-community==0.0.18)
  Downloading yarl-1.9.4-cp312-cp312-win_amd64.whl.metadata (32 kB)
Collecting marshmallow&lt;4.0.0,&gt;=3.18.0 (from dataclasses-json&lt;0.7,&gt;=0.5.7-&gt;langchain-community==0.0.18)
  Using cached marshmallow-3.20.2-py3-none-any.whl.metadata (7.5 kB)
Collecting typing-inspect&lt;1,&gt;=0.4.0 (from dataclasses-json&lt;0.7,&gt;=0.5.7-&gt;langchain-community==0.0.18)
  Using cached typing_inspect-0.9.0-py3-none-any.whl.metadata (1.5 kB)
Collecting anyio&lt;5,&gt;=3 (from langchain-core&lt;0.2,&gt;=0.1.19-&gt;langchain-community==0.0.18)
  Using cached anyio-4.2.0-py3-none-any.whl.metadata (4.6 kB)
Collecting jsonpatch&lt;2.0,&gt;=1.33 (from langchain-core&lt;0.2,&gt;=0.1.19-&gt;langchain-community==0.0.18)
  Using cached jsonpatch-1.33-py2.py3-none-any.whl.metadata (3.0 kB)
Collecting langsmith&lt;0.1,&gt;=0.0.83 (from langchain-community==0.0.18)
  Using cached langsmith-0.0.87-py3-none-any.whl.metadata (10 kB)
Requirement already satisfied: packaging&lt;24.0,&gt;=23.2 in c:\users\adnegrau\appdata\local\programs\python\python312\lib\site-packages (from langchain-core&lt;0.2,&gt;=0.1.19-&gt;langchain-community==0.0.18) (23.2)
Collecting pydantic&lt;3,&gt;=1 (from langchain-core&lt;0.2,&gt;=0.1.19-&gt;langchain-community==0.0.18)
  Downloading pydantic-2.6.1-py3-none-any.whl.metadata (83 kB)
     ---------------------------------------- 0.0/83.5 kB ? eta -:--:--
     ---------------------------------------- 83.5/83.5 kB 4.6 MB/s eta 0:00:00
Requirement already satisfied: charset-normalizer&lt;4,&gt;=2 in c:\users\adnegrau\appdata\local\programs\python\python312\lib\site-packages (from requests&lt;3,&gt;=2-&gt;langchain-community==0.0.18) (3.3.2)
Requirement already satisfied: idna&lt;4,&gt;=2.5 in c:\users\adnegrau\appdata\local\programs\python\python312\lib\site-packages (from requests&lt;3,&gt;=2-&gt;langchain-community==0.0.18) (3.6)
Requirement already satisfied: urllib3&lt;3,&gt;=1.21.1 in c:\users\adnegrau\appdata\local\programs\python\python312\lib\site-packages (from requests&lt;3,&gt;=2-&gt;langchain-community==0.0.18) (2.1.0)
Requirement already satisfied: certifi&gt;=2017.4.17 in c:\users\adnegrau\appdata\local\programs\python\python312\lib\site-packages (from requests&lt;3,&gt;=2-&gt;langchain-community==0.0.18) (2023.11.17)
Requirement already satisfied: typing-extensions&gt;=4.6.0 in c:\users\adnegrau\appdata\local\programs\python\python312\lib\site-packages (from SQLAlchemy&lt;3,&gt;=1.4-&gt;langchain-community==0.0.18) (4.9.0)
Requirement already satisfied: greenlet!=0.4.17 in c:\users\adnegrau\appdata\local\programs\python\python312\lib\site-packages (from SQLAlchemy&lt;3,&gt;=1.4-&gt;langchain-community==0.0.18) (3.0.3)
Collecting sniffio&gt;=1.1 (from anyio&lt;5,&gt;=3-&gt;langchain-core&lt;0.2,&gt;=0.1.19-&gt;langchain-community==0.0.18)
  Using cached sniffio-1.3.0-py3-none-any.whl (10 kB)
Collecting jsonpointer&gt;=1.9 (from jsonpatch&lt;2.0,&gt;=1.33-&gt;langchain-core&lt;0.2,&gt;=0.1.19-&gt;langchain-community==0.0.18)
  Using cached jsonpointer-2.4-py2.py3-none-any.whl.metadata (2.5 kB)
Collecting annotated-types&gt;=0.4.0 (from pydantic&lt;3,&gt;=1-&gt;langchain-core&lt;0.2,&gt;=0.1.19-&gt;langchain-community==0.0.18)
  Using cached annotated_types-0.6.0-py3-none-any.whl.metadata (12 kB)
Collecting pydantic-core==2.16.2 (from pydantic&lt;3,&gt;=1-&gt;langchain-core&lt;0.2,&gt;=0.1.19-&gt;langchain-community==0.0.18)
  Downloading pydantic_core-2.16.2-cp312-none-win_amd64.whl.metadata (6.6 kB)
Collecting mypy-extensions&gt;=0.3.0 (from typing-inspect&lt;1,&gt;=0.4.0-&gt;dataclasses-json&lt;0.7,&gt;=0.5.7-&gt;langchain-community==0.0.18)
  Using cached mypy_extensions-1.0.0-py3-none-any.whl (4.7 kB)
Using cached langchain_community-0.0.18-py3-none-any.whl (1.6 MB)
Downloading aiohttp-3.9.3-cp312-cp312-win_amd64.whl (363 kB)
   ---------------------------------------- 0.0/363.4 kB ? eta -:--:--
   --------------------------------------- 363.4/363.4 kB 22.1 MB/s eta 0:00:00
Using cached dataclasses_json-0.6.4-py3-none-any.whl (28 kB)
Using cached langchain_core-0.1.22-py3-none-any.whl (239 kB)
Using cached langsmith-0.0.87-py3-none-any.whl (55 kB)
Using cached tenacity-8.2.3-py3-none-any.whl (24 kB)
Using cached anyio-4.2.0-py3-none-any.whl (85 kB)
Downloading frozenlist-1.4.1-cp312-cp312-win_amd64.whl (50 kB)
   ---------------------------------------- 0.0/50.5 kB ? eta -:--:--
   ---------------------------------------- 50.5/50.5 kB ? eta 0:00:00
Using cached jsonpatch-1.33-py2.py3-none-any.whl (12 kB)
Using cached marshmallow-3.20.2-py3-none-any.whl (49 kB)
Downloading multidict-6.0.5-cp312-cp312-win_amd64.whl (27 kB)
Downloading pydantic-2.6.1-py3-none-any.whl (394 kB)
   ---------------------------------------- 0.0/394.8 kB ? eta -:--:--
   --------------------------------------- 394.8/394.8 kB 25.6 MB/s eta 0:00:00
Downloading pydantic_core-2.16.2-cp312-none-win_amd64.whl (1.9 MB)
   ---------------------------------------- 0.0/1.9 MB ? eta -:--:--
   --------------------------- ------------ 1.3/1.9 MB 27.4 MB/s eta 0:00:01
   ---------------------------------------- 1.9/1.9 MB 29.7 MB/s eta 0:00:00
Using cached typing_inspect-0.9.0-py3-none-any.whl (8.8 kB)
Downloading yarl-1.9.4-cp312-cp312-win_amd64.whl (76 kB)
   ---------------------------------------- 0.0/76.4 kB ? eta -:--:--
   ---------------------------------------- 76.4/76.4 kB 4.1 MB/s eta 0:00:00
Using cached annotated_types-0.6.0-py3-none-any.whl (12 kB)
Using cached jsonpointer-2.4-py2.py3-none-any.whl (7.8 kB)
Installing collected packages: tenacity, sniffio, pydantic-core, mypy-extensions, multidict, marshmallow, jsonpointer, frozenlist, annotated-types, yarl, typing-inspect, pydantic, jsonpatch, anyio, aiosignal, langsmith, dataclasses-json, aiohttp, langchain-core, langchain-community
Successfully installed aiohttp-3.9.3 aiosignal-1.3.1 annotated-types-0.6.0 anyio-4.2.0 dataclasses-json-0.6.4 frozenlist-1.4.1 jsonpatch-1.33 jsonpointer-2.4 langchain-community-0.0.18 langchain-core-0.1.22 langsmith-0.0.87 marshmallow-3.20.2 multidict-6.0.5 mypy-extensions-1.0.0 pydantic-2.6.1 pydantic-core-2.16.2 sniffio-1.3.0 tenacity-8.2.3 typing-inspect-0.9.0 yarl-1.9.4
</pre></div>
</div>
<div class="output stream highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>Note: you may need to restart the kernel to use updated packages.
</pre></div>
</div>
<div class="output stderr highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>ERROR: Ignored the following yanked versions: 0.8.3, 0.10.19.dev18
ERROR: Ignored the following versions that require a different python version: 0.12.0 Requires-Python &gt;=3.9.0,&lt;3.12; 0.12.2 Requires-Python &gt;=3.9.0,&lt;3.12; 0.12.3 Requires-Python &gt;=3.9.0,&lt;3.12; 0.12.4 Requires-Python &gt;=3.9.0,&lt;3.12
ERROR: Could not find a version that satisfies the requirement unstructured==0.12.3 (from versions: 0.0.1.dev0, 0.2.0, 0.2.1, 0.2.2, 0.2.3, 0.2.4, 0.2.5, 0.2.6.dev1, 0.3.0, 0.3.1, 0.3.2, 0.3.3, 0.3.4, 0.3.5, 0.4.0, 0.4.1, 0.4.2, 0.4.3, 0.4.4, 0.4.6, 0.4.7, 0.4.8, 0.4.9, 0.4.10, 0.4.11, 0.4.12, 0.4.13, 0.4.14, 0.4.15, 0.4.16, 0.5.0, 0.5.1, 0.5.2, 0.5.3, 0.5.4, 0.5.6, 0.5.7, 0.5.8, 0.5.9, 0.5.10, 0.5.11, 0.5.12, 0.5.13, 0.6.0, 0.6.1, 0.6.2, 0.6.3, 0.6.4, 0.6.5, 0.6.6, 0.6.7, 0.6.8, 0.6.9, 0.6.10, 0.6.11, 0.7.0, 0.7.1, 0.7.2, 0.7.3, 0.7.4, 0.7.5, 0.7.6, 0.7.7, 0.7.8, 0.7.9, 0.7.10, 0.7.11, 0.7.12, 0.8.0, 0.8.1, 0.8.4, 0.8.5, 0.8.6, 0.8.7, 0.8.8, 0.9.0, 0.9.1, 0.9.2, 0.9.3, 0.10.0, 0.10.1, 0.10.2, 0.10.4, 0.10.5, 0.10.6, 0.10.7, 0.10.8, 0.10.9, 0.10.10, 0.10.11, 0.10.12, 0.10.13, 0.10.14, 0.10.15, 0.10.16, 0.10.18, 0.10.19, 0.10.20, 0.10.21, 0.10.22, 0.10.23, 0.10.24, 0.10.25, 0.10.26, 0.10.27, 0.10.28, 0.10.29, 0.10.30, 0.11.0, 0.11.1, 0.11.2, 0.11.4, 0.11.5, 0.11.6, 0.11.7, 0.11.8)
ERROR: No matching distribution found for unstructured==0.12.3
</pre></div>
</div>
<div class="output stream highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>Collecting unstructured-client==0.17.0
  Using cached unstructured_client-0.17.0-py3-none-any.whl.metadata (4.9 kB)
Requirement already satisfied: certifi&gt;=2023.7.22 in c:\users\adnegrau\appdata\local\programs\python\python312\lib\site-packages (from unstructured-client==0.17.0) (2023.11.17)
Requirement already satisfied: charset-normalizer&gt;=3.2.0 in c:\users\adnegrau\appdata\local\programs\python\python312\lib\site-packages (from unstructured-client==0.17.0) (3.3.2)
Collecting dataclasses-json-speakeasy&gt;=0.5.11 (from unstructured-client==0.17.0)
  Using cached dataclasses_json_speakeasy-0.5.11-py3-none-any.whl.metadata (25 kB)
Requirement already satisfied: idna&gt;=3.4 in c:\users\adnegrau\appdata\local\programs\python\python312\lib\site-packages (from unstructured-client==0.17.0) (3.6)
Collecting jsonpath-python&gt;=1.0.6 (from unstructured-client==0.17.0)
  Using cached jsonpath_python-1.0.6-py3-none-any.whl (7.6 kB)
Requirement already satisfied: marshmallow&gt;=3.19.0 in c:\users\adnegrau\appdata\local\programs\python\python312\lib\site-packages (from unstructured-client==0.17.0) (3.20.2)
Requirement already satisfied: mypy-extensions&gt;=1.0.0 in c:\users\adnegrau\appdata\local\programs\python\python312\lib\site-packages (from unstructured-client==0.17.0) (1.0.0)
Requirement already satisfied: packaging&gt;=23.1 in c:\users\adnegrau\appdata\local\programs\python\python312\lib\site-packages (from unstructured-client==0.17.0) (23.2)
Requirement already satisfied: python-dateutil&gt;=2.8.2 in c:\users\adnegrau\appdata\local\programs\python\python312\lib\site-packages (from unstructured-client==0.17.0) (2.8.2)
Requirement already satisfied: requests&gt;=2.31.0 in c:\users\adnegrau\appdata\local\programs\python\python312\lib\site-packages (from unstructured-client==0.17.0) (2.31.0)
Requirement already satisfied: six&gt;=1.16.0 in c:\users\adnegrau\appdata\local\programs\python\python312\lib\site-packages (from unstructured-client==0.17.0) (1.16.0)
Requirement already satisfied: typing-inspect&gt;=0.9.0 in c:\users\adnegrau\appdata\local\programs\python\python312\lib\site-packages (from unstructured-client==0.17.0) (0.9.0)
Requirement already satisfied: typing-extensions&gt;=4.7.1 in c:\users\adnegrau\appdata\local\programs\python\python312\lib\site-packages (from unstructured-client==0.17.0) (4.9.0)
Requirement already satisfied: urllib3&gt;=1.26.18 in c:\users\adnegrau\appdata\local\programs\python\python312\lib\site-packages (from unstructured-client==0.17.0) (2.1.0)
Using cached unstructured_client-0.17.0-py3-none-any.whl (20 kB)
Using cached dataclasses_json_speakeasy-0.5.11-py3-none-any.whl (28 kB)
Installing collected packages: jsonpath-python, dataclasses-json-speakeasy, unstructured-client
Successfully installed dataclasses-json-speakeasy-0.5.11 jsonpath-python-1.0.6 unstructured-client-0.17.0
Note: you may need to restart the kernel to use updated packages.
</pre></div>
</div>
<div class="output stream highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>Collecting langchain==0.1.5
  Using cached langchain-0.1.5-py3-none-any.whl.metadata (13 kB)
Requirement already satisfied: PyYAML&gt;=5.3 in c:\users\adnegrau\appdata\local\programs\python\python312\lib\site-packages (from langchain==0.1.5) (6.0.1)
Requirement already satisfied: SQLAlchemy&lt;3,&gt;=1.4 in c:\users\adnegrau\appdata\local\programs\python\python312\lib\site-packages (from langchain==0.1.5) (2.0.25)
Requirement already satisfied: aiohttp&lt;4.0.0,&gt;=3.8.3 in c:\users\adnegrau\appdata\local\programs\python\python312\lib\site-packages (from langchain==0.1.5) (3.9.3)
Requirement already satisfied: dataclasses-json&lt;0.7,&gt;=0.5.7 in c:\users\adnegrau\appdata\local\programs\python\python312\lib\site-packages (from langchain==0.1.5) (0.6.4)
Requirement already satisfied: jsonpatch&lt;2.0,&gt;=1.33 in c:\users\adnegrau\appdata\local\programs\python\python312\lib\site-packages (from langchain==0.1.5) (1.33)
Requirement already satisfied: langchain-community&lt;0.1,&gt;=0.0.17 in c:\users\adnegrau\appdata\local\programs\python\python312\lib\site-packages (from langchain==0.1.5) (0.0.18)
Requirement already satisfied: langchain-core&lt;0.2,&gt;=0.1.16 in c:\users\adnegrau\appdata\local\programs\python\python312\lib\site-packages (from langchain==0.1.5) (0.1.22)
Requirement already satisfied: langsmith&lt;0.1,&gt;=0.0.83 in c:\users\adnegrau\appdata\local\programs\python\python312\lib\site-packages (from langchain==0.1.5) (0.0.87)
Requirement already satisfied: numpy&lt;2,&gt;=1 in c:\users\adnegrau\appdata\local\programs\python\python312\lib\site-packages (from langchain==0.1.5) (1.26.3)
Requirement already satisfied: pydantic&lt;3,&gt;=1 in c:\users\adnegrau\appdata\local\programs\python\python312\lib\site-packages (from langchain==0.1.5) (2.6.1)
Requirement already satisfied: requests&lt;3,&gt;=2 in c:\users\adnegrau\appdata\local\programs\python\python312\lib\site-packages (from langchain==0.1.5) (2.31.0)
Requirement already satisfied: tenacity&lt;9.0.0,&gt;=8.1.0 in c:\users\adnegrau\appdata\local\programs\python\python312\lib\site-packages (from langchain==0.1.5) (8.2.3)
Requirement already satisfied: aiosignal&gt;=1.1.2 in c:\users\adnegrau\appdata\local\programs\python\python312\lib\site-packages (from aiohttp&lt;4.0.0,&gt;=3.8.3-&gt;langchain==0.1.5) (1.3.1)
Requirement already satisfied: attrs&gt;=17.3.0 in c:\users\adnegrau\appdata\local\programs\python\python312\lib\site-packages (from aiohttp&lt;4.0.0,&gt;=3.8.3-&gt;langchain==0.1.5) (23.2.0)
Requirement already satisfied: frozenlist&gt;=1.1.1 in c:\users\adnegrau\appdata\local\programs\python\python312\lib\site-packages (from aiohttp&lt;4.0.0,&gt;=3.8.3-&gt;langchain==0.1.5) (1.4.1)
Requirement already satisfied: multidict&lt;7.0,&gt;=4.5 in c:\users\adnegrau\appdata\local\programs\python\python312\lib\site-packages (from aiohttp&lt;4.0.0,&gt;=3.8.3-&gt;langchain==0.1.5) (6.0.5)
Requirement already satisfied: yarl&lt;2.0,&gt;=1.0 in c:\users\adnegrau\appdata\local\programs\python\python312\lib\site-packages (from aiohttp&lt;4.0.0,&gt;=3.8.3-&gt;langchain==0.1.5) (1.9.4)
Requirement already satisfied: marshmallow&lt;4.0.0,&gt;=3.18.0 in c:\users\adnegrau\appdata\local\programs\python\python312\lib\site-packages (from dataclasses-json&lt;0.7,&gt;=0.5.7-&gt;langchain==0.1.5) (3.20.2)
Requirement already satisfied: typing-inspect&lt;1,&gt;=0.4.0 in c:\users\adnegrau\appdata\local\programs\python\python312\lib\site-packages (from dataclasses-json&lt;0.7,&gt;=0.5.7-&gt;langchain==0.1.5) (0.9.0)
Requirement already satisfied: jsonpointer&gt;=1.9 in c:\users\adnegrau\appdata\local\programs\python\python312\lib\site-packages (from jsonpatch&lt;2.0,&gt;=1.33-&gt;langchain==0.1.5) (2.4)
Requirement already satisfied: anyio&lt;5,&gt;=3 in c:\users\adnegrau\appdata\local\programs\python\python312\lib\site-packages (from langchain-core&lt;0.2,&gt;=0.1.16-&gt;langchain==0.1.5) (4.2.0)
Requirement already satisfied: packaging&lt;24.0,&gt;=23.2 in c:\users\adnegrau\appdata\local\programs\python\python312\lib\site-packages (from langchain-core&lt;0.2,&gt;=0.1.16-&gt;langchain==0.1.5) (23.2)
Requirement already satisfied: annotated-types&gt;=0.4.0 in c:\users\adnegrau\appdata\local\programs\python\python312\lib\site-packages (from pydantic&lt;3,&gt;=1-&gt;langchain==0.1.5) (0.6.0)
Requirement already satisfied: pydantic-core==2.16.2 in c:\users\adnegrau\appdata\local\programs\python\python312\lib\site-packages (from pydantic&lt;3,&gt;=1-&gt;langchain==0.1.5) (2.16.2)
Requirement already satisfied: typing-extensions&gt;=4.6.1 in c:\users\adnegrau\appdata\local\programs\python\python312\lib\site-packages (from pydantic&lt;3,&gt;=1-&gt;langchain==0.1.5) (4.9.0)
Requirement already satisfied: charset-normalizer&lt;4,&gt;=2 in c:\users\adnegrau\appdata\local\programs\python\python312\lib\site-packages (from requests&lt;3,&gt;=2-&gt;langchain==0.1.5) (3.3.2)
Requirement already satisfied: idna&lt;4,&gt;=2.5 in c:\users\adnegrau\appdata\local\programs\python\python312\lib\site-packages (from requests&lt;3,&gt;=2-&gt;langchain==0.1.5) (3.6)
Requirement already satisfied: urllib3&lt;3,&gt;=1.21.1 in c:\users\adnegrau\appdata\local\programs\python\python312\lib\site-packages (from requests&lt;3,&gt;=2-&gt;langchain==0.1.5) (2.1.0)
Requirement already satisfied: certifi&gt;=2017.4.17 in c:\users\adnegrau\appdata\local\programs\python\python312\lib\site-packages (from requests&lt;3,&gt;=2-&gt;langchain==0.1.5) (2023.11.17)
Requirement already satisfied: greenlet!=0.4.17 in c:\users\adnegrau\appdata\local\programs\python\python312\lib\site-packages (from SQLAlchemy&lt;3,&gt;=1.4-&gt;langchain==0.1.5) (3.0.3)
Requirement already satisfied: sniffio&gt;=1.1 in c:\users\adnegrau\appdata\local\programs\python\python312\lib\site-packages (from anyio&lt;5,&gt;=3-&gt;langchain-core&lt;0.2,&gt;=0.1.16-&gt;langchain==0.1.5) (1.3.0)
Requirement already satisfied: mypy-extensions&gt;=0.3.0 in c:\users\adnegrau\appdata\local\programs\python\python312\lib\site-packages (from typing-inspect&lt;1,&gt;=0.4.0-&gt;dataclasses-json&lt;0.7,&gt;=0.5.7-&gt;langchain==0.1.5) (1.0.0)
Using cached langchain-0.1.5-py3-none-any.whl (806 kB)
Installing collected packages: langchain
Successfully installed langchain-0.1.5
Note: you may need to restart the kernel to use updated packages.
</pre></div>
</div>
</div>
</div>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="kn">import</span> <span class="nn">tqdm</span>
<span class="kn">import</span> <span class="nn">glob</span>
<span class="kn">from</span> <span class="nn">langchain_community.document_loaders</span> <span class="kn">import</span> <span class="n">UnstructuredMarkdownLoader</span><span class="p">,</span> <span class="n">UnstructuredFileLoader</span>
<span class="kn">from</span> <span class="nn">langchain.text_splitter</span> <span class="kn">import</span> <span class="n">MarkdownTextSplitter</span><span class="p">,</span> <span class="n">NLTKTextSplitter</span><span class="p">,</span> <span class="n">RecursiveCharacterTextSplitter</span>

<span class="c1"># Code also https://github.com/microsoft/rag-openai/blob/438999a5470bef7946fa1c8714ed1090e1ed40c3/samples/searchEvaluation/customskills/utils/chunker/text_chunker.py</span>
</pre></div>
</div>
</div>
<div class="cell_output docutils container">
<div class="output traceback highlight-ipythontb notranslate"><div class="highlight"><pre><span></span><span class="gt">---------------------------------------------------------------------------</span>
<span class="ne">ModuleNotFoundError</span><span class="g g-Whitespace">                       </span>Traceback (most recent call last)
<span class="n">Cell</span> <span class="n">In</span><span class="p">[</span><span class="mi">2</span><span class="p">],</span> <span class="n">line</span> <span class="mi">1</span>
<span class="ne">----&gt; </span><span class="mi">1</span> <span class="kn">import</span> <span class="nn">tqdm</span>
<span class="g g-Whitespace">      </span><span class="mi">2</span> <span class="kn">import</span> <span class="nn">glob</span>
<span class="g g-Whitespace">      </span><span class="mi">3</span> <span class="kn">from</span> <span class="nn">langchain_community.document_loaders</span> <span class="kn">import</span> <span class="n">UnstructuredMarkdownLoader</span><span class="p">,</span> <span class="n">UnstructuredFileLoader</span>

<span class="ne">ModuleNotFoundError</span>: No module named &#39;tqdm&#39;
</pre></div>
</div>
</div>
</div>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="o">%</span><span class="k">pip</span> install &quot;unstructured[md]&quot;
</pre></div>
</div>
</div>
</div>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="k">def</span> <span class="nf">load_documents_from_folder</span><span class="p">(</span><span class="n">path</span><span class="p">:</span> <span class="nb">str</span><span class="p">)</span> <span class="o">-&gt;</span> <span class="nb">list</span><span class="p">[</span><span class="nb">str</span><span class="p">]:</span>
    <span class="nb">print</span><span class="p">(</span><span class="s2">&quot;Loading documents...&quot;</span><span class="p">)</span>
    <span class="n">markdown_documents</span> <span class="o">=</span> <span class="p">[]</span>
    <span class="k">for</span> <span class="n">file</span> <span class="ow">in</span> <span class="n">tqdm</span><span class="o">.</span><span class="n">tqdm</span><span class="p">(</span><span class="n">glob</span><span class="o">.</span><span class="n">glob</span><span class="p">(</span><span class="n">path</span><span class="p">,</span> <span class="n">recursive</span><span class="o">=</span><span class="kc">True</span><span class="p">)):</span>
        <span class="n">loader</span> <span class="o">=</span> <span class="n">UnstructuredFileLoader</span><span class="p">(</span><span class="n">file</span><span class="p">)</span> 
        <span class="n">document</span> <span class="o">=</span> <span class="n">loader</span><span class="o">.</span><span class="n">load</span><span class="p">()</span>
        <span class="n">markdown_documents</span><span class="o">.</span><span class="n">append</span><span class="p">(</span><span class="n">document</span><span class="p">)</span>
    <span class="k">return</span> <span class="n">markdown_documents</span>
</pre></div>
</div>
</div>
</div>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="n">markdown_documents</span> <span class="o">=</span> <span class="n">load_documents_from_folder</span><span class="p">(</span><span class="s2">&quot;../data/docs/**/*.md&quot;</span><span class="p">)</span>
<span class="c1"># TODO: Move this to a Storage Account?</span>
</pre></div>
</div>
</div>
<div class="cell_output docutils container">
<div class="output stream highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>Loading documents...
</pre></div>
</div>
<div class="output stderr highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>100%|██████████| 777/777 [00:57&lt;00:00, 13.57it/s]
</pre></div>
</div>
</div>
</div>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="k">def</span> <span class="nf">create_chunks</span><span class="p">(</span><span class="n">documents</span><span class="p">:</span> <span class="nb">list</span><span class="p">)</span> <span class="o">-&gt;</span> <span class="nb">list</span><span class="p">:</span>
    <span class="nb">print</span><span class="p">(</span><span class="s2">&quot;Creating chunks...&quot;</span><span class="p">)</span>
    <span class="n">markdown_splitter</span> <span class="o">=</span> <span class="n">MarkdownTextSplitter</span><span class="o">.</span><span class="n">from_tiktoken_encoder</span><span class="p">(</span>
        <span class="n">chunk_size</span><span class="o">=</span><span class="mi">300</span><span class="p">,</span> <span class="n">chunk_overlap</span><span class="o">=</span><span class="mi">30</span>
    <span class="p">)</span>
    <span class="n">lengths</span> <span class="o">=</span> <span class="p">{}</span>
    <span class="n">all_chunks</span> <span class="o">=</span> <span class="p">{}</span>
    <span class="n">chunk_id</span> <span class="o">=</span> <span class="mi">0</span>
    <span class="k">for</span> <span class="n">document</span> <span class="ow">in</span> <span class="n">tqdm</span><span class="o">.</span><span class="n">tqdm</span><span class="p">(</span><span class="n">documents</span><span class="p">):</span>
        <span class="n">current_chunks_text_list</span> <span class="o">=</span> <span class="n">markdown_splitter</span><span class="o">.</span><span class="n">split_text</span><span class="p">(</span>
            <span class="n">document</span><span class="p">[</span><span class="mi">0</span><span class="p">]</span><span class="o">.</span><span class="n">page_content</span>
        <span class="p">)</span>  <span class="c1"># output = [&quot;content chunk1&quot;, &quot;content chunk2&quot;, ...]</span>

        <span class="k">for</span> <span class="n">i</span><span class="p">,</span> <span class="n">chunk</span> <span class="ow">in</span> <span class="nb">enumerate</span><span class="p">(</span>
            <span class="n">current_chunks_text_list</span>
        <span class="p">):</span>  <span class="c1"># (0, &quot;content chunk1&quot;), (1, &quot;content chunk2&quot;), ...</span>
            <span class="n">current_chunk_dict</span> <span class="o">=</span> <span class="p">{</span>
                <span class="s2">&quot;chunk_id&quot;</span><span class="p">:</span> <span class="n">i</span><span class="p">,</span>
                <span class="s2">&quot;chunk_text&quot;</span><span class="p">:</span> <span class="n">chunk</span><span class="p">,</span>
                <span class="s2">&quot;source&quot;</span><span class="p">:</span> <span class="n">document</span><span class="p">[</span><span class="mi">0</span><span class="p">]</span><span class="o">.</span><span class="n">metadata</span><span class="p">[</span><span class="s2">&quot;source&quot;</span><span class="p">],</span>
            <span class="p">}</span>
            <span class="n">current_id_str</span> <span class="o">=</span> <span class="sa">f</span><span class="s2">&quot;chunk</span><span class="si">{</span><span class="n">chunk_id</span><span class="si">}</span><span class="s2">_</span><span class="si">{</span><span class="n">i</span><span class="si">}</span><span class="s2">&quot;</span>
            <span class="n">all_chunks</span><span class="p">[</span><span class="n">current_id_str</span><span class="p">]</span> <span class="o">=</span> <span class="n">current_chunk_dict</span>

        <span class="n">chunk_id</span> <span class="o">+=</span> <span class="mi">1</span>

        <span class="n">n_chunks</span> <span class="o">=</span> <span class="nb">len</span><span class="p">(</span><span class="n">current_chunks_text_list</span><span class="p">)</span>
        <span class="c1"># lengths = {[Number of chunks]: [number of documents with that number of chunks]}</span>
        <span class="k">if</span> <span class="n">n_chunks</span> <span class="ow">not</span> <span class="ow">in</span> <span class="n">lengths</span><span class="p">:</span>
            <span class="n">lengths</span><span class="p">[</span><span class="n">n_chunks</span><span class="p">]</span> <span class="o">=</span> <span class="mi">1</span>
        <span class="k">else</span><span class="p">:</span>
            <span class="n">lengths</span><span class="p">[</span><span class="n">n_chunks</span><span class="p">]</span> <span class="o">+=</span> <span class="mi">1</span>

    <span class="nb">print</span><span class="p">(</span><span class="n">lengths</span><span class="p">)</span>
    <span class="k">return</span> <span class="n">all_chunks</span>
</pre></div>
</div>
</div>
</div>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="n">chunks</span> <span class="o">=</span> <span class="n">create_chunks</span><span class="p">(</span><span class="n">markdown_documents</span><span class="p">)</span>
</pre></div>
</div>
</div>
<div class="cell_output docutils container">
<div class="output stream highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>Creating chunks...
</pre></div>
</div>
<div class="output stderr highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>100%|██████████| 777/777 [00:02&lt;00:00, 277.03it/s]
</pre></div>
</div>
<div class="output stream highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>{1: 145, 2: 137, 4: 69, 5: 74, 7: 43, 12: 8, 16: 6, 32: 1, 18: 7, 3: 98, 8: 30, 6: 58, 20: 2, 9: 20, 13: 13, 15: 10, 10: 11, 17: 2, 11: 19, 14: 12, 43: 1, 25: 1, 26: 2, 22: 3, 30: 1, 19: 2, 38: 1, 29: 1}
</pre></div>
</div>
<div class="output stderr highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>
</pre></div>
</div>
</div>
</div>
<p>In this experiment, we will use OpenAI ada for embedding the chunks</p>
<p>Upload files to a storage account so we can create an Indexer
<a class="github reference external" href="https://github.com/microsoft/rag-openai/blob/438999a5470bef7946fa1c8714ed1090e1ed40c3/samples/searchEvaluation/upload_files.py">microsoft/rag-openai</a></p>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="o">%</span><span class="k">pip</span> install python-dotenv
</pre></div>
</div>
</div>
<div class="cell_output docutils container">
<div class="output stream highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>Note: you may need to restart the kernel to use updated packages.Requirement already satisfied: python-dotenv in c:\projects\workshop2024\.venv\lib\site-packages (1.0.0)
</pre></div>
</div>
<div class="output stderr highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>[notice] A new release of pip is available: 23.3.2 -&gt; 24.0
[notice] To update, run: python.exe -m pip install --upgrade pip
</pre></div>
</div>
</div>
</div>
</section>
</section>

    <script type="text/x-thebe-config">
    {
        requestKernel: true,
        binderOptions: {
            repo: "binder-examples/jupyter-stacks-datascience",
            ref: "master",
        },
        codeMirrorConfig: {
            theme: "abcdef",
            mode: "python"
        },
        kernelOptions: {
            name: "python3",
            path: "./."
        },
        predefinedOutput: true
    }
    </script>
    <script>kernelName = 'python3'</script>

                </article>
              

              
              
              
              
                <footer class="prev-next-footer">
                  
<div class="prev-next-area">
    <a class="left-prev"
       href="3.experiment.html"
       title="previous page">
      <i class="fa-solid fa-angle-left"></i>
      <div class="prev-next-info">
        <p class="prev-next-subtitle">previous</p>
        <p class="prev-next-title">3. Experiments</p>
      </div>
    </a>
    <a class="right-next"
       href="3.2.experiment_embedding.html"
       title="next page">
      <div class="prev-next-info">
        <p class="prev-next-subtitle">next</p>
        <p class="prev-next-title">3.2. Embeddings</p>
      </div>
      <i class="fa-solid fa-angle-right"></i>
    </a>
</div>
                </footer>
              
            </div>
            
            
              
                <div class="bd-sidebar-secondary bd-toc"><div class="sidebar-secondary-items sidebar-secondary__inner">


  <div class="sidebar-secondary-item">
  <div class="page-toc tocsection onthispage">
    <i class="fa-solid fa-list"></i> Contents
  </div>
  <nav class="bd-toc-nav page-toc">
    <ul class="visible nav section-nav flex-column">
<li class="toc-h2 nav-item toc-entry"><a class="reference internal nav-link" href="#why-chunking-size-matters">Why Chunking Size Matters</a></li>
</ul>
  </nav></div>

</div></div>
              
            
          </div>
          <footer class="bd-footer-content">
            
<div class="bd-footer-content__inner container">
  
  <div class="footer-item">
    
<p class="component-author">
By Raouf Aliouat & Adina Stoll
</p>

  </div>
  
  <div class="footer-item">
    

  <p class="copyright">
    
      © Copyright 2022.
      <br/>
    
  </p>

  </div>
  
  <div class="footer-item">
    
  </div>
  
  <div class="footer-item">
    
  </div>
  
</div>
          </footer>
        

      </main>
    </div>
  </div>
  
  <!-- Scripts loaded after <body> so the DOM is not blocked -->
  <script src="_static/scripts/bootstrap.js?digest=8d27b9dea8ad943066ae"></script>
<script src="_static/scripts/pydata-sphinx-theme.js?digest=8d27b9dea8ad943066ae"></script>

  <footer class="bd-footer">
  </footer>
  </body>
</html>