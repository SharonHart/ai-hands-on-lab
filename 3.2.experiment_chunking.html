
<!DOCTYPE html>


<html lang="en" data-content_root="./" >

  <head>
    <meta charset="utf-8" />
    <meta name="viewport" content="width=device-width, initial-scale=1.0" /><meta name="viewport" content="width=device-width, initial-scale=1" />

    <title>3.2. Chunking Experiment &#8212; AI Workshop</title>
  
  
  
  <script data-cfasync="false">
    document.documentElement.dataset.mode = localStorage.getItem("mode") || "";
    document.documentElement.dataset.theme = localStorage.getItem("theme") || "light";
  </script>
  
  <!-- Loaded before other Sphinx assets -->
  <link href="_static/styles/theme.css?digest=8d27b9dea8ad943066ae" rel="stylesheet" />
<link href="_static/styles/bootstrap.css?digest=8d27b9dea8ad943066ae" rel="stylesheet" />
<link href="_static/styles/pydata-sphinx-theme.css?digest=8d27b9dea8ad943066ae" rel="stylesheet" />

  
  <link href="_static/vendor/fontawesome/6.5.1/css/all.min.css?digest=8d27b9dea8ad943066ae" rel="stylesheet" />
  <link rel="preload" as="font" type="font/woff2" crossorigin href="_static/vendor/fontawesome/6.5.1/webfonts/fa-solid-900.woff2" />
<link rel="preload" as="font" type="font/woff2" crossorigin href="_static/vendor/fontawesome/6.5.1/webfonts/fa-brands-400.woff2" />
<link rel="preload" as="font" type="font/woff2" crossorigin href="_static/vendor/fontawesome/6.5.1/webfonts/fa-regular-400.woff2" />

    <link rel="stylesheet" type="text/css" href="_static/pygments.css?v=fa44fd50" />
    <link rel="stylesheet" type="text/css" href="_static/styles/sphinx-book-theme.css?v=384b581d" />
    <link rel="stylesheet" type="text/css" href="_static/togglebutton.css?v=13237357" />
    <link rel="stylesheet" type="text/css" href="_static/copybutton.css?v=76b2166b" />
    <link rel="stylesheet" type="text/css" href="_static/mystnb.4510f1fc1dee50b3e5859aac5469c37c29e427902b24a333a5f9fcb2f0b3ac41.css" />
    <link rel="stylesheet" type="text/css" href="_static/sphinx-thebe.css?v=4fa983c6" />
    <link rel="stylesheet" type="text/css" href="_static/design-style.1e8bd061cd6da7fc9cf755528e8ffc24.min.css?v=0a3b3ea7" />
  
  <!-- Pre-loaded scripts that we'll load fully later -->
  <link rel="preload" as="script" href="_static/scripts/bootstrap.js?digest=8d27b9dea8ad943066ae" />
<link rel="preload" as="script" href="_static/scripts/pydata-sphinx-theme.js?digest=8d27b9dea8ad943066ae" />
  <script src="_static/vendor/fontawesome/6.5.1/js/all.min.js?digest=8d27b9dea8ad943066ae"></script>

    <script src="_static/documentation_options.js?v=9eb32ce0"></script>
    <script src="_static/doctools.js?v=888ff710"></script>
    <script src="_static/sphinx_highlight.js?v=dc90522c"></script>
    <script src="_static/clipboard.min.js?v=a7894cd8"></script>
    <script src="_static/copybutton.js?v=f281be69"></script>
    <script src="_static/scripts/sphinx-book-theme.js?v=efea14e4"></script>
    <script>let toggleHintShow = 'Click to show';</script>
    <script>let toggleHintHide = 'Click to hide';</script>
    <script>let toggleOpenOnPrint = 'true';</script>
    <script src="_static/togglebutton.js?v=4a39c7ea"></script>
    <script>var togglebuttonSelector = '.toggle, .admonition.dropdown';</script>
    <script src="_static/design-tabs.js?v=36754332"></script>
    <script>const THEBE_JS_URL = "https://unpkg.com/thebe@0.8.2/lib/index.js"; const thebe_selector = ".thebe,.cell"; const thebe_selector_input = "pre"; const thebe_selector_output = ".output, .cell_output"</script>
    <script async="async" src="_static/sphinx-thebe.js?v=c100c467"></script>
    <script>var togglebuttonSelector = '.toggle, .admonition.dropdown';</script>
    <script>const THEBE_JS_URL = "https://unpkg.com/thebe@0.8.2/lib/index.js"; const thebe_selector = ".thebe,.cell"; const thebe_selector_input = "pre"; const thebe_selector_output = ".output, .cell_output"</script>
    <script>DOCUMENTATION_OPTIONS.pagename = '3.2.experiment_chunking';</script>
    <link rel="index" title="Index" href="genindex.html" />
    <link rel="search" title="Search" href="search.html" />
    <link rel="next" title="3.3. End-to-end evaluation" href="3.3.end_to_end_evaluation.html" />
    <link rel="prev" title="3.1. Embeddings Experiment" href="3.1.experiment_embedding.html" />
  <meta name="viewport" content="width=device-width, initial-scale=1"/>
  <meta name="docsearch:language" content="en"/>
  </head>
  
  
  <body data-bs-spy="scroll" data-bs-target=".bd-toc-nav" data-offset="180" data-bs-root-margin="0px 0px -60%" data-default-mode="">

  
  
  <a id="pst-skip-link" class="skip-link" href="#main-content">Skip to main content</a>
  
  <div id="pst-scroll-pixel-helper"></div>
  
  <button type="button" class="btn rounded-pill" id="pst-back-to-top">
    <i class="fa-solid fa-arrow-up"></i>
    Back to top
  </button>

  
  <input type="checkbox"
          class="sidebar-toggle"
          name="__primary"
          id="__primary"/>
  <label class="overlay overlay-primary" for="__primary"></label>
  
  <input type="checkbox"
          class="sidebar-toggle"
          name="__secondary"
          id="__secondary"/>
  <label class="overlay overlay-secondary" for="__secondary"></label>
  
  <div class="search-button__wrapper">
    <div class="search-button__overlay"></div>
    <div class="search-button__search-container">
<form class="bd-search d-flex align-items-center"
      action="search.html"
      method="get">
  <i class="fa-solid fa-magnifying-glass"></i>
  <input type="search"
         class="form-control"
         name="q"
         id="search-input"
         placeholder="Search this book..."
         aria-label="Search this book..."
         autocomplete="off"
         autocorrect="off"
         autocapitalize="off"
         spellcheck="false"/>
  <span class="search-button__kbd-shortcut"><kbd class="kbd-shortcut__modifier">Ctrl</kbd>+<kbd>K</kbd></span>
</form></div>
  </div>
  
    <header class="bd-header navbar navbar-expand-lg bd-navbar">
    </header>
  

  <div class="bd-container">
    <div class="bd-container__inner bd-page-width">
      
      
      
      <div class="bd-sidebar-primary bd-sidebar">
        

  
  <div class="sidebar-header-items sidebar-primary__section">
    
    
    
    
  </div>
  
    <div class="sidebar-primary-items__start sidebar-primary__section">
        <div class="sidebar-primary-item">

  

<a class="navbar-brand logo" href="0.intro.html">
  
  
  
  
  
    
    
      
    
    
    <img src="_static/logo.png" class="logo__image only-light" alt="AI Workshop - Home"/>
    <script>document.write(`<img src="_static/logo.png" class="logo__image only-dark" alt="AI Workshop - Home"/>`);</script>
  
  
</a></div>
        <div class="sidebar-primary-item">

 <script>
 document.write(`
   <button class="btn navbar-btn search-button-field search-button__button" title="Search" aria-label="Search" data-bs-placement="bottom" data-bs-toggle="tooltip">
    <i class="fa-solid fa-magnifying-glass"></i>
    <span class="search-button__default-text">Search</span>
    <span class="search-button__kbd-shortcut"><kbd class="kbd-shortcut__modifier">Ctrl</kbd>+<kbd class="kbd-shortcut__modifier">K</kbd></span>
   </button>
 `);
 </script></div>
        <div class="sidebar-primary-item"><nav class="bd-links bd-docs-nav" aria-label="Main">
    <div class="bd-toc-item navbar-nav active">
        
        <ul class="nav bd-sidenav bd-sidenav__home-link">
            <li class="toctree-l1">
                <a class="reference internal" href="0.intro.html">
                    Welcome
                </a>
            </li>
        </ul>
        <p aria-level="2" class="caption" role="heading"><span class="caption-text">1. Introduction</span></p>
<ul class="nav bd-sidenav">
<li class="toctree-l1"><a class="reference internal" href="1.setup.html">Setup</a></li>
<li class="toctree-l1"><a class="reference internal" href="1.rag-intro.html">RAG - Introduction</a></li>
<li class="toctree-l1"><a class="reference internal" href="1.context.html">Context</a></li>
</ul>
<p aria-level="2" class="caption" role="heading"><span class="caption-text">2. Implementation</span></p>
<ul class="nav bd-sidenav">
<li class="toctree-l1"><a class="reference internal" href="2.rag-implementation.html">RAG - Baseline implementation</a></li>
</ul>
<p aria-level="2" class="caption" role="heading"><span class="caption-text">3. Experimentation</span></p>
<ul class="current nav bd-sidenav">
<li class="toctree-l1"><a class="reference internal" href="3.0.experiments.html">Experiments</a></li>
<li class="toctree-l1"><a class="reference internal" href="3.1.experiment_embedding.html">3.1. Embeddings Experiment</a></li>
<li class="toctree-l1 current active"><a class="current reference internal" href="#">3.2. Chunking Experiment</a></li>
<li class="toctree-l1"><a class="reference internal" href="3.3.end_to_end_evaluation.html">3.3. End-to-end evaluation</a></li>
</ul>
<p aria-level="2" class="caption" role="heading"><span class="caption-text">4. Production</span></p>
<ul class="nav bd-sidenav">
<li class="toctree-l1"><a class="reference internal" href="4.post-production.html">Post-production</a></li>
</ul>
<p aria-level="2" class="caption" role="heading"><span class="caption-text">Appendix</span></p>
<ul class="nav bd-sidenav">
<li class="toctree-l1"><a class="reference internal" href="5.1.generation-qa.html">Generation of synthetic data</a></li>



</ul>

    </div>
</nav></div>
    </div>
  
  
  <div class="sidebar-primary-items__end sidebar-primary__section">
  </div>
  
  <div id="rtd-footer-container"></div>


      </div>
      
      <main id="main-content" class="bd-main">
        
        

<div class="sbt-scroll-pixel-helper"></div>

          <div class="bd-content">
            <div class="bd-article-container">
              
              <div class="bd-header-article">
<div class="header-article-items header-article__inner">
  
    <div class="header-article-items__start">
      
        <div class="header-article-item"><label class="sidebar-toggle primary-toggle btn btn-sm" for="__primary" title="Toggle primary sidebar" data-bs-placement="bottom" data-bs-toggle="tooltip">
  <span class="fa-solid fa-bars"></span>
</label></div>
      
    </div>
  
  
    <div class="header-article-items__end">
      
        <div class="header-article-item">

<div class="article-header-buttons">





<div class="dropdown dropdown-source-buttons">
  <button class="btn dropdown-toggle" type="button" data-bs-toggle="dropdown" aria-expanded="false" aria-label="Source repositories">
    <i class="fab fa-github"></i>
  </button>
  <ul class="dropdown-menu">
      
      
      
      <li><a href="https://github.com/executablebooks/jupyter-book" target="_blank"
   class="btn btn-sm btn-source-repository-button dropdown-item"
   title="Source repository"
   data-bs-placement="left" data-bs-toggle="tooltip"
>
  

<span class="btn__icon-container">
  <i class="fab fa-github"></i>
  </span>
<span class="btn__text-container">Repository</span>
</a>
</li>
      
      
      
      
      <li><a href="https://github.com/executablebooks/jupyter-book/issues/new?title=Issue%20on%20page%20%2F3.2.experiment_chunking.html&body=Your%20issue%20content%20here." target="_blank"
   class="btn btn-sm btn-source-issues-button dropdown-item"
   title="Open an issue"
   data-bs-placement="left" data-bs-toggle="tooltip"
>
  

<span class="btn__icon-container">
  <i class="fas fa-lightbulb"></i>
  </span>
<span class="btn__text-container">Open issue</span>
</a>
</li>
      
  </ul>
</div>






<div class="dropdown dropdown-download-buttons">
  <button class="btn dropdown-toggle" type="button" data-bs-toggle="dropdown" aria-expanded="false" aria-label="Download this page">
    <i class="fas fa-download"></i>
  </button>
  <ul class="dropdown-menu">
      
      
      
      <li><a href="_sources/3.2.experiment_chunking.ipynb" target="_blank"
   class="btn btn-sm btn-download-source-button dropdown-item"
   title="Download source file"
   data-bs-placement="left" data-bs-toggle="tooltip"
>
  

<span class="btn__icon-container">
  <i class="fas fa-file"></i>
  </span>
<span class="btn__text-container">.ipynb</span>
</a>
</li>
      
      
      
      
      <li>
<button onclick="window.print()"
  class="btn btn-sm btn-download-pdf-button dropdown-item"
  title="Print to PDF"
  data-bs-placement="left" data-bs-toggle="tooltip"
>
  

<span class="btn__icon-container">
  <i class="fas fa-file-pdf"></i>
  </span>
<span class="btn__text-container">.pdf</span>
</button>
</li>
      
  </ul>
</div>




<button onclick="toggleFullScreen()"
  class="btn btn-sm btn-fullscreen-button"
  title="Fullscreen mode"
  data-bs-placement="bottom" data-bs-toggle="tooltip"
>
  

<span class="btn__icon-container">
  <i class="fas fa-expand"></i>
  </span>

</button>



<script>
document.write(`
  <button class="btn btn-sm navbar-btn theme-switch-button" title="light/dark" aria-label="light/dark" data-bs-placement="bottom" data-bs-toggle="tooltip">
    <span class="theme-switch nav-link" data-mode="light"><i class="fa-solid fa-sun fa-lg"></i></span>
    <span class="theme-switch nav-link" data-mode="dark"><i class="fa-solid fa-moon fa-lg"></i></span>
    <span class="theme-switch nav-link" data-mode="auto"><i class="fa-solid fa-circle-half-stroke fa-lg"></i></span>
  </button>
`);
</script>


<script>
document.write(`
  <button class="btn btn-sm navbar-btn search-button search-button__button" title="Search" aria-label="Search" data-bs-placement="bottom" data-bs-toggle="tooltip">
    <i class="fa-solid fa-magnifying-glass fa-lg"></i>
  </button>
`);
</script>
<label class="sidebar-toggle secondary-toggle btn btn-sm" for="__secondary"title="Toggle secondary sidebar" data-bs-placement="bottom" data-bs-toggle="tooltip">
    <span class="fa-solid fa-list"></span>
</label>
</div></div>
      
    </div>
  
</div>
</div>
              
              

<div id="jb-print-docs-body" class="onlyprint">
    <h1>3.2. Chunking Experiment</h1>
    <!-- Table of contents -->
    <div id="print-main-content">
        <div id="jb-print-toc">
            
            <div>
                <h2> Contents </h2>
            </div>
            <nav aria-label="Page">
                <ul class="visible nav section-nav flex-column">
<li class="toc-h2 nav-item toc-entry"><a class="reference internal nav-link" href="#experiment-overview">Experiment Overview</a></li>
<li class="toc-h2 nav-item toc-entry"><a class="reference internal nav-link" href="#why-does-chunking-matter">Why does chunking matter?</a></li>
<li class="toc-h2 nav-item toc-entry"><a class="reference internal nav-link" href="#setup">Setup</a></li>
<li class="toc-h2 nav-item toc-entry"><a class="reference internal nav-link" href="#markdown-header-text-splitter">1. Markdown Header Text Splitter</a><ul class="nav section-nav flex-column">
<li class="toc-h3 nav-item toc-entry"><a class="reference internal nav-link" href="#overview">Overview</a></li>
<li class="toc-h3 nav-item toc-entry"><a class="reference internal nav-link" href="#example">Example</a></li>
<li class="toc-h3 nav-item toc-entry"><a class="reference internal nav-link" href="#chunk-the-data">Chunk the data</a></li>
<li class="toc-h3 nav-item toc-entry"><a class="reference internal nav-link" href="#analysis">Analysis</a></li>
</ul>
</li>
<li class="toc-h2 nav-item toc-entry"><a class="reference internal nav-link" href="#markdown-text-splitter-using-tiktoken-encoder">2. Markdown Text Splitter using tiktoken encoder</a><ul class="nav section-nav flex-column">
<li class="toc-h3 nav-item toc-entry"><a class="reference internal nav-link" href="#id1">Overview</a></li>
<li class="toc-h3 nav-item toc-entry"><a class="reference internal nav-link" href="#id2">Example</a></li>
<li class="toc-h3 nav-item toc-entry"><a class="reference internal nav-link" href="#id3">Chunk the data</a></li>
<li class="toc-h3 nav-item toc-entry"><a class="reference internal nav-link" href="#id4">Analysis</a></li>
</ul>
</li>
<li class="toc-h2 nav-item toc-entry"><a class="reference internal nav-link" href="#semantic-chunking">3. Semantic Chunking</a><ul class="nav section-nav flex-column">
<li class="toc-h3 nav-item toc-entry"><a class="reference internal nav-link" href="#id5">Overview</a></li>
<li class="toc-h3 nav-item toc-entry"><a class="reference internal nav-link" href="#id6">Example</a></li>
</ul>
</li>
<li class="toc-h2 nav-item toc-entry"><a class="reference internal nav-link" href="#evaluation">📈 Evaluation</a><ul class="nav section-nav flex-column">
<li class="toc-h3 nav-item toc-entry"><a class="reference internal nav-link" href="#create-3-search-indexes">Create 3 search indexes</a></li>
<li class="toc-h3 nav-item toc-entry"><a class="reference internal nav-link" href="#evaluation-dataset">📊 Evaluation Dataset</a></li>
<li class="toc-h3 nav-item toc-entry"><a class="reference internal nav-link" href="#evaluation-metrics">🎯Evaluation Metrics</a></li>
<li class="toc-h3 nav-item toc-entry"><a class="reference internal nav-link" href="#evaluate-the-markdown-header-text-splitter-took-3-min">👩‍💻 1. Evaluate the Markdown Header Text Splitter - took 3 min</a></li>
<li class="toc-h3 nav-item toc-entry"><a class="reference internal nav-link" href="#evaluate-the-markdown-text-splitter-using-tiktoken-encode">👩‍💻 2. Evaluate the Markdown Text Splitter using tiktoken encode</a></li>
<li class="toc-h3 nav-item toc-entry"><a class="reference internal nav-link" href="#evaluate-the-semantic-chunking-strategy">👩‍💻 3. Evaluate the semantic chunking strategy</a></li>
</ul>
</li>
<li class="toc-h2 nav-item toc-entry"><a class="reference internal nav-link" href="#conclusions">💡 Conclusions</a></li>
</ul>
            </nav>
        </div>
    </div>
</div>

              
                
<div id="searchbox"></div>
                <article class="bd-article">
                  
  <section class="tex2jax_ignore mathjax_ignore" id="chunking-experiment">
<h1>3.2. Chunking Experiment<a class="headerlink" href="#chunking-experiment" title="Link to this heading">#</a></h1>
<p>There are multiple methods of ingestion, depending on the type of data. For example, unstructured data such as documents or web pages can be split into chunks and embedded into vectors, while structured data such as tables or databases can be summarized or converted into natural language. In our case, since we are working with text data, we will look into different chunking strategies.</p>
<!--
The search solution is comprised of both **ingestion** and **retrieval**. One does not exist without the other. While other experiments are focused on data retrieval, ingestion plays equal importance in the effectiveness of the search solution. During this experiment, we will look at various chunking strategies. -->
<section id="experiment-overview">
<h2>Experiment Overview<a class="headerlink" href="#experiment-overview" title="Link to this heading">#</a></h2>
<!-- Certain aspects of data ingestion need to be experimented as part of the experimentation phase: -->
<!-- # Chunking Strategy

Code also https://github.com/microsoft/rag-openai/blob/438999a5470bef7946fa1c8714ed1090e1ed40c3/samples/searchEvaluation/customskills/utils/chunker/text_chunker.py

There are multiple methods of ingestion, depending on the type of data. For example, unstructured data such as documents or web pages can be split into chunks and embedded into vectors, while structured data such as tables or databases can be summarized or converted into natural language. In our case, since we are working with unstructured text data, we will look into different chunking strategies.
 -->
<table class="table">
<thead>
<tr class="row-odd"><th class="head"><p><strong>Topic</strong></p></th>
<th class="head"><p>Description</p></th>
</tr>
</thead>
<tbody>
<tr class="row-even"><td><p>📝 <strong>Hypothesis</strong></p></td>
<td><p>Exploratory hypothesis: “Can introducing a new chunking strategy improve system’s performance?”</p></td>
</tr>
<tr class="row-odd"><td><p>⚖️ <strong>Comparison</strong></p></td>
<td><p>We will compare <a class="reference external" href="https://python.langchain.com/docs/modules/data_connection/document_transformers/markdown_header_metadata">MarkdownHeaderTextSplitter</a>, <a class="reference external" href="https://python.langchain.com/docs/modules/data_connection/document_transformers/markdown_header_metadata">MarkdownTextSplitter</a> and semantic chunking strategy (<a class="reference external" href="https://python.langchain.com/docs/modules/data_connection/document_transformers/semantic-chunker">SemanticChunker</a>).</p></td>
</tr>
<tr class="row-even"><td><p>🎯 <strong>Evaluation Metrics</strong></p></td>
<td><p>We will look at Accuracy and Cosine Similarity to compare the performance.</p></td>
</tr>
<tr class="row-odd"><td><p>📊 <strong>Data</strong></p></td>
<td><p>The data that we will use consists of <a class="reference internal" href="#../data/docs/code-with-engineering/"><span class="xref myst">code-with-engineering</span></a> and <a class="reference internal" href="#../data/docs/code-with-mlops/"><span class="xref myst">code-with-mlops</span></a> sections from Solution Ops repository.</p></td>
</tr>
<tr class="row-even"><td><p>📊 <strong>Evaluation Dataset</strong></p></td>
<td><p><a class="reference download internal" download="" href="_downloads/bcdfa9bc085268b4c728951df4f5374c/qa_pairs_solutionops.json"><span class="xref download myst">300 question-answer</span></a> pairs generated from <a class="reference internal" href="#../data/docs/code-with-engineering/"><span class="xref myst">code-with-engineering</span></a> and <a class="reference internal" href="#../data/docs/code-with-mlops/"><span class="xref myst">code-with-mlops</span></a> sections from Solution Ops repository. See <a class="reference internal" href="5.1.generation-qa.html"><span class="std std-doc">Generation QA Notebook</span></a> for insights on how they were generated.</p></td>
</tr>
</tbody>
</table>
<div class="admonition note">
<p class="admonition-title">Note</p>
<p>Our goal here is not to identify which chunking strategy is the “best” in general but rather to demonstrate how the choice of chunking may have a non-trivial impact on the ultimate outcome from the RAG solution.</p>
</div>
<!-- 📝**Hypothesis**

Exploratory hypothesis: "Can introducing a new chunking strategy improve system's performance?"

🎯 **Evaluation Metrics**

For this experiment we will look at Accuracy and Cosine Similarity to compare the performance.

📊 **Data**

In this experiment, the data that we would like to chunk consists of the first 200 documents from the Solution Ops Playbook. -->
<!-- The metrics used for document retrieval evaluation. -->
<!-- [Learnings fromm other engagements](https://github.com/microsoft/rag-openai/blob/main/topics/RAG_EnablingSearch.md#learnings-from-engagements-1) -->
<!-- https://vectara.com/blog/grounded-generation-done-right-chunking/#:~:text=In%20the%20context%20of%20Grounded%20Generation%2C%20chunking%20is,find%20natural%20segments%20like%20complete%20sentences%20or%20paragraphs. -->
<!-- https://towardsdatascience.com/how-to-chunk-text-data-a-comparative-analysis-3858c4a0997a -->
<!-- https://blog.llamaindex.ai/evaluating-the-ideal-chunk-size-for-a-rag-system-using-llamaindex-6207e5d3fec5

Example code: https://github.com/Azure/azure-search-vector-samples/blob/main/demo-python/code/data-chunking/textsplit-data-chunking-example.ipynb

Read [Common Chunking Technique](https://learn.microsoft.com/en-us/azure/search/semantic-search-overview), [Content overlap considerations](https://learn.microsoft.com/en-us/azure/search/vector-search-how-to-chunk-documents#content-overlap-considerations), [Simple example of how to create chunks with sentences](https://learn.microsoft.com/en-us/azure/search/vector-search-how-to-chunk-documents#content-overlap-considerations)

CODE: https://github.com/microsoft/rag-openai/blob/438999a5470bef7946fa1c8714ed1090e1ed40c3/samples/searchEvaluation/customskills/utils/chunker/text_chunker.py -->
</section>
<section id="why-does-chunking-matter">
<h2>Why does chunking matter?<a class="headerlink" href="#why-does-chunking-matter" title="Link to this heading">#</a></h2>
<p>When processing data, splitting the source documents into chunks requires care and expertise to ensure the resulting chunks are small enough to be effective during fact retrieval but not too small so that enough context is provided during summarization.</p>
<p><em>Why do we even need to chunk?</em> you may ask.</p>
<p>The models used to generate embedding vectors have maximum limits on the text fragments provided as input. For example, the maximum length of input text for the Azure OpenAI embedding models is <strong>8,191</strong> tokens. Given that each token is around 4 characters of text for common OpenAI models, this maximum limit is equivalent to around 6000 words of text. If you’re using these models to generate embeddings, it’s critical that the input text stays under the limit. Partitioning your content into chunks ensures that your data can be processed by the model used for indexing and queries.</p>
<p>In our workshop, we work with text documents. Refer to <a class="reference external" href="https://python.langchain.com/docs/modules/data_connection/document_transformers/#types-of-text-splitters">Types of Tet Splitters</a> for an overview of supported options from LangChain.</p>
</section>
<section id="setup">
<h2>Setup<a class="headerlink" href="#setup" title="Link to this heading">#</a></h2>
<p>Import necessary libraries</p>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="o">%</span><span class="k">run</span> -i ./pre-requisites.ipynb

<span class="kn">import</span> <span class="nn">glob</span>
<span class="kn">from</span> <span class="nn">langchain_community.document_loaders</span> <span class="kn">import</span> <span class="n">UnstructuredFileLoader</span>
<span class="kn">import</span> <span class="nn">os</span>
<span class="kn">import</span> <span class="nn">pandas</span> <span class="k">as</span> <span class="nn">pd</span>
<span class="kn">import</span> <span class="nn">plotly.express</span> <span class="k">as</span> <span class="nn">px</span>
</pre></div>
</div>
</div>
</div>
<p>Let’s load the documents from Solution Ops Playbook (from <code class="docutils literal notranslate"><span class="pre">code-with-engineering</span></code> and <code class="docutils literal notranslate"><span class="pre">code-with-mlops</span></code> folders):</p>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="k">def</span> <span class="nf">load_documents_from_folder</span><span class="p">(</span><span class="n">paths</span><span class="p">)</span> <span class="o">-&gt;</span> <span class="nb">list</span><span class="p">[</span><span class="nb">str</span><span class="p">]:</span>
    <span class="n">markdown_documents</span> <span class="o">=</span> <span class="p">[]</span>
    <span class="k">for</span> <span class="n">path</span> <span class="ow">in</span> <span class="n">paths</span><span class="p">:</span>
        <span class="k">for</span> <span class="n">file</span> <span class="ow">in</span> <span class="n">glob</span><span class="o">.</span><span class="n">glob</span><span class="p">(</span><span class="n">path</span><span class="p">,</span> <span class="n">recursive</span><span class="o">=</span><span class="kc">True</span><span class="p">):</span>
            <span class="n">loader</span> <span class="o">=</span> <span class="n">UnstructuredFileLoader</span><span class="p">(</span><span class="n">file</span><span class="p">)</span>
            <span class="n">document</span> <span class="o">=</span> <span class="n">loader</span><span class="o">.</span><span class="n">load</span><span class="p">()</span>
            <span class="n">markdown_documents</span><span class="o">.</span><span class="n">append</span><span class="p">(</span><span class="n">document</span><span class="p">)</span>
    <span class="k">return</span> <span class="n">markdown_documents</span>
</pre></div>
</div>
</div>
</div>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="o">%%capture</span> --no-display
<span class="kn">import</span> <span class="nn">ntpath</span>
<span class="n">paths</span> <span class="o">=</span> <span class="p">[</span><span class="s2">&quot;../data/docs/code-with-engineering/**/*.md&quot;</span><span class="p">,</span><span class="s2">&quot;../data/docs/code-with-mlops/**/*.md&quot;</span><span class="p">]</span>

<span class="k">if</span> <span class="n">os</span><span class="o">.</span><span class="n">name</span> <span class="o">==</span> <span class="s2">&quot;nt&quot;</span><span class="p">:</span>
    <span class="n">paths</span> <span class="o">=</span> <span class="p">[</span><span class="n">ntpath</span><span class="o">.</span><span class="n">normpath</span><span class="p">(</span><span class="n">path</span><span class="p">)</span> <span class="k">for</span> <span class="n">path</span> <span class="ow">in</span> <span class="n">paths</span><span class="p">]</span>
<span class="n">documents</span> <span class="o">=</span> <span class="n">load_documents_from_folder</span><span class="p">(</span>
    <span class="n">paths</span><span class="p">)</span>
</pre></div>
</div>
</div>
</div>
</section>
<section id="markdown-header-text-splitter">
<h2>1. Markdown Header Text Splitter<a class="headerlink" href="#markdown-header-text-splitter" title="Link to this heading">#</a></h2>
<section id="overview">
<h3>Overview<a class="headerlink" href="#overview" title="Link to this heading">#</a></h3>
<p>In this approach we will leverage the fact that our documents are markdown files and we will consider that the markdown pages are well structured. Therefore, we will split using the markdown headers.</p>
</section>
<section id="example">
<h3>Example<a class="headerlink" href="#example" title="Link to this heading">#</a></h3>
<p>Let’s load LangChain’s <code class="docutils literal notranslate"><span class="pre">MarkdownHeaderTextSplitter</span></code> to split the text for us</p>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="kn">from</span> <span class="nn">langchain.text_splitter</span> <span class="kn">import</span> <span class="n">MarkdownHeaderTextSplitter</span>
</pre></div>
</div>
</div>
</div>
<p>For example, if we want to split this markdown:</p>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="n">markdown_document</span> <span class="o">=</span> <span class="s2">&quot;# Foo</span><span class="se">\n\n</span><span class="s2"> ## Bar</span><span class="se">\n\n</span><span class="s2">Hi this is Jim  </span><span class="se">\n</span><span class="s2">Hi this is Joe</span><span class="se">\n\n</span><span class="s2"> ## Baz</span><span class="se">\n\n</span><span class="s2"> Hi this is Molly&quot;</span>
</pre></div>
</div>
</div>
</div>
<p>We can specify the headers to split on:</p>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="n">headers_to_split_on</span> <span class="o">=</span> <span class="p">[</span>
    <span class="p">(</span><span class="s2">&quot;#&quot;</span><span class="p">,</span> <span class="s2">&quot;Header 1&quot;</span><span class="p">),</span>
    <span class="p">(</span><span class="s2">&quot;##&quot;</span><span class="p">,</span> <span class="s2">&quot;Header 2&quot;</span><span class="p">),</span>
    <span class="p">(</span><span class="s2">&quot;###&quot;</span><span class="p">,</span> <span class="s2">&quot;Header 3&quot;</span><span class="p">),</span>
<span class="p">]</span>
</pre></div>
</div>
</div>
</div>
<p>Let’s look at the output:</p>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="n">markdown_splitter</span> <span class="o">=</span> <span class="n">MarkdownHeaderTextSplitter</span><span class="p">(</span>
    <span class="n">headers_to_split_on</span><span class="o">=</span><span class="n">headers_to_split_on</span><span class="p">)</span>
<span class="n">md_header_splits</span> <span class="o">=</span> <span class="n">markdown_splitter</span><span class="o">.</span><span class="n">split_text</span><span class="p">(</span><span class="n">markdown_document</span><span class="p">)</span>
<span class="n">md_header_splits</span>
</pre></div>
</div>
</div>
<div class="cell_output docutils container">
<div class="output text_plain highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>[Document(page_content=&#39;Hi this is Jim\nHi this is Joe&#39;, metadata={&#39;Header 1&#39;: &#39;Foo&#39;, &#39;Header 2&#39;: &#39;Bar&#39;}),
 Document(page_content=&#39;Hi this is Molly&#39;, metadata={&#39;Header 1&#39;: &#39;Foo&#39;, &#39;Header 2&#39;: &#39;Baz&#39;})]
</pre></div>
</div>
</div>
</div>
</section>
<section id="chunk-the-data">
<h3>Chunk the data<a class="headerlink" href="#chunk-the-data" title="Link to this heading">#</a></h3>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="k">def</span> <span class="nf">create_chunks_md_headers</span><span class="p">(</span><span class="n">documents</span><span class="p">:</span> <span class="nb">list</span><span class="p">)</span> <span class="o">-&gt;</span> <span class="nb">list</span><span class="p">:</span>
    <span class="nb">print</span><span class="p">(</span><span class="s2">&quot;Creating chunks...&quot;</span><span class="p">)</span>
    <span class="n">headers_to_split_on</span> <span class="o">=</span> <span class="p">[</span>
        <span class="p">(</span><span class="s2">&quot;#&quot;</span><span class="p">,</span> <span class="s2">&quot;Header 1&quot;</span><span class="p">),</span>
        <span class="p">(</span><span class="s2">&quot;##&quot;</span><span class="p">,</span> <span class="s2">&quot;Header 2&quot;</span><span class="p">),</span>
        <span class="p">(</span><span class="s2">&quot;###&quot;</span><span class="p">,</span> <span class="s2">&quot;Header 3&quot;</span><span class="p">),</span>
    <span class="p">]</span>

    <span class="n">markdown_splitter</span> <span class="o">=</span> <span class="n">MarkdownHeaderTextSplitter</span><span class="p">(</span>
        <span class="n">headers_to_split_on</span><span class="o">=</span><span class="n">headers_to_split_on</span><span class="p">,</span> <span class="n">strip_headers</span><span class="o">=</span><span class="kc">False</span><span class="p">)</span>

    <span class="n">chunk_id</span> <span class="o">=</span> <span class="mi">0</span>

    <span class="n">chunks</span> <span class="o">=</span> <span class="p">{</span>
        <span class="s2">&quot;chunkId&quot;</span><span class="p">:</span> <span class="p">[],</span>
        <span class="s2">&quot;chunkContent&quot;</span><span class="p">:</span> <span class="p">[],</span>
        <span class="s2">&quot;source&quot;</span><span class="p">:</span> <span class="p">[]</span>
    <span class="p">}</span>

    <span class="k">for</span> <span class="n">document</span> <span class="ow">in</span> <span class="n">documents</span><span class="p">:</span>
        <span class="n">current_chunks_text_list</span> <span class="o">=</span> <span class="n">markdown_splitter</span><span class="o">.</span><span class="n">split_text</span><span class="p">(</span>
            <span class="n">document</span><span class="p">[</span><span class="mi">0</span><span class="p">]</span><span class="o">.</span><span class="n">page_content</span><span class="p">)</span>

        <span class="k">for</span> <span class="n">i</span><span class="p">,</span> <span class="n">chunk</span> <span class="ow">in</span> <span class="nb">enumerate</span><span class="p">(</span><span class="n">current_chunks_text_list</span><span class="p">):</span>
            <span class="n">chunks</span><span class="p">[</span><span class="s1">&#39;chunkId&#39;</span><span class="p">]</span><span class="o">.</span><span class="n">append</span><span class="p">(</span><span class="sa">f</span><span class="s2">&quot;chunk</span><span class="si">{</span><span class="n">chunk_id</span><span class="si">}</span><span class="s2">_</span><span class="si">{</span><span class="n">i</span><span class="si">}</span><span class="s2">&quot;</span><span class="p">)</span>
            <span class="n">chunks</span><span class="p">[</span><span class="s1">&#39;chunkContent&#39;</span><span class="p">]</span><span class="o">.</span><span class="n">append</span><span class="p">(</span><span class="n">chunk</span><span class="o">.</span><span class="n">page_content</span><span class="p">)</span>
            <span class="n">chunks</span><span class="p">[</span><span class="s1">&#39;source&#39;</span><span class="p">]</span><span class="o">.</span><span class="n">append</span><span class="p">(</span><span class="n">document</span><span class="p">[</span><span class="mi">0</span><span class="p">]</span><span class="o">.</span><span class="n">metadata</span><span class="p">[</span><span class="s1">&#39;source&#39;</span><span class="p">])</span>

        <span class="n">chunk_id</span> <span class="o">+=</span> <span class="mi">1</span>
    <span class="k">return</span> <span class="n">chunks</span>
</pre></div>
</div>
</div>
</div>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="n">chunks_with_md_headers</span> <span class="o">=</span> <span class="n">create_chunks_md_headers</span><span class="p">(</span>
    <span class="n">documents</span><span class="p">)</span>

<span class="n">df_chunks_with_md_headers</span> <span class="o">=</span> <span class="n">pd</span><span class="o">.</span><span class="n">DataFrame</span><span class="p">(</span><span class="n">chunks_with_md_headers</span><span class="p">)</span>
<span class="n">df_chunks_with_md_headers</span><span class="o">.</span><span class="n">head</span><span class="p">()</span>
</pre></div>
</div>
</div>
<div class="cell_output docutils container">
<div class="output stream highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>Creating chunks...
</pre></div>
</div>
<div class="output text_html"><div>
<style scoped>
    .dataframe tbody tr th:only-of-type {
        vertical-align: middle;
    }

    .dataframe tbody tr th {
        vertical-align: top;
    }

    .dataframe thead th {
        text-align: right;
    }
</style>
<table border="1" class="dataframe">
  <thead>
    <tr style="text-align: right;">
      <th></th>
      <th>chunkId</th>
      <th>chunkContent</th>
      <th>source</th>
    </tr>
  </thead>
  <tbody>
    <tr>
      <th>0</th>
      <td>chunk0_0</td>
      <td>Structure of a Sprint  \nThe purpose of this d...</td>
      <td>../data/docs/code-with-engineering/SPRINT-STRU...</td>
    </tr>
    <tr>
      <th>1</th>
      <td>chunk1_0</td>
      <td>Who We Are  \nOur team, ISE (Industry Solution...</td>
      <td>../data/docs/code-with-engineering/ISE.md</td>
    </tr>
    <tr>
      <th>2</th>
      <td>chunk2_0</td>
      <td>Engineering Fundamentals Checklist  \nThis che...</td>
      <td>../data/docs/code-with-engineering/ENG-FUNDAME...</td>
    </tr>
    <tr>
      <th>3</th>
      <td>chunk3_0</td>
      <td>ISE Code-With Engineering Playbook  \nAn engin...</td>
      <td>../data/docs/code-with-engineering/index.md</td>
    </tr>
    <tr>
      <th>4</th>
      <td>chunk4_0</td>
      <td>Work Item ID  \nFor more information about how...</td>
      <td>../data/docs/code-with-engineering/code-review...</td>
    </tr>
  </tbody>
</table>
</div></div></div>
</div>
</section>
<section id="analysis">
<h3>Analysis<a class="headerlink" href="#analysis" title="Link to this heading">#</a></h3>
<p>Let’s look at the distribution of lengths in the chunks.</p>
<p>We create a new colum called chunk_text_length which contains the length of the chunk_text column.</p>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="n">df_chunks_with_md_headers</span><span class="p">[</span><span class="s1">&#39;chunk_text_length&#39;</span><span class="p">]</span> <span class="o">=</span> <span class="n">df_chunks_with_md_headers</span><span class="p">[</span><span class="s1">&#39;chunkContent&#39;</span><span class="p">]</span><span class="o">.</span><span class="n">apply</span><span class="p">(</span>
    <span class="k">lambda</span> <span class="n">x</span><span class="p">:</span> <span class="nb">len</span><span class="p">(</span><span class="n">x</span><span class="o">.</span><span class="n">split</span><span class="p">()))</span>
<span class="n">df_chunks_with_md_headers</span><span class="o">.</span><span class="n">head</span><span class="p">(</span><span class="mi">10</span><span class="p">)</span>
</pre></div>
</div>
</div>
<div class="cell_output docutils container">
<div class="output text_html"><div>
<style scoped>
    .dataframe tbody tr th:only-of-type {
        vertical-align: middle;
    }

    .dataframe tbody tr th {
        vertical-align: top;
    }

    .dataframe thead th {
        text-align: right;
    }
</style>
<table border="1" class="dataframe">
  <thead>
    <tr style="text-align: right;">
      <th></th>
      <th>chunkId</th>
      <th>chunkContent</th>
      <th>source</th>
      <th>chunk_text_length</th>
    </tr>
  </thead>
  <tbody>
    <tr>
      <th>0</th>
      <td>chunk0_0</td>
      <td>Structure of a Sprint  \nThe purpose of this d...</td>
      <td>../data/docs/code-with-engineering/SPRINT-STRU...</td>
      <td>468</td>
    </tr>
    <tr>
      <th>1</th>
      <td>chunk1_0</td>
      <td>Who We Are  \nOur team, ISE (Industry Solution...</td>
      <td>../data/docs/code-with-engineering/ISE.md</td>
      <td>263</td>
    </tr>
    <tr>
      <th>2</th>
      <td>chunk2_0</td>
      <td>Engineering Fundamentals Checklist  \nThis che...</td>
      <td>../data/docs/code-with-engineering/ENG-FUNDAME...</td>
      <td>793</td>
    </tr>
    <tr>
      <th>3</th>
      <td>chunk3_0</td>
      <td>ISE Code-With Engineering Playbook  \nAn engin...</td>
      <td>../data/docs/code-with-engineering/index.md</td>
      <td>357</td>
    </tr>
    <tr>
      <th>4</th>
      <td>chunk4_0</td>
      <td>Work Item ID  \nFor more information about how...</td>
      <td>../data/docs/code-with-engineering/code-review...</td>
      <td>325</td>
    </tr>
    <tr>
      <th>5</th>
      <td>chunk5_0</td>
      <td>FAQ  \nThis is a list of questions / frequentl...</td>
      <td>../data/docs/code-with-engineering/code-review...</td>
      <td>548</td>
    </tr>
    <tr>
      <th>6</th>
      <td>chunk6_0</td>
      <td>Code Reviews  \nDevelopers working on projects...</td>
      <td>../data/docs/code-with-engineering/code-review...</td>
      <td>111</td>
    </tr>
    <tr>
      <th>7</th>
      <td>chunk7_0</td>
      <td>Inclusion in Code Review  \nBelow are some poi...</td>
      <td>../data/docs/code-with-engineering/code-review...</td>
      <td>852</td>
    </tr>
    <tr>
      <th>8</th>
      <td>chunk8_0</td>
      <td>Pull Requests  \nChanges to any main codebase ...</td>
      <td>../data/docs/code-with-engineering/code-review...</td>
      <td>653</td>
    </tr>
    <tr>
      <th>9</th>
      <td>chunk9_0</td>
      <td>Code Review Tools  \nCustomize ADO  \nTask boa...</td>
      <td>../data/docs/code-with-engineering/code-review...</td>
      <td>392</td>
    </tr>
  </tbody>
</table>
</div></div></div>
</div>
<p>Let’s plot the distribution:</p>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="c1"># fig = px.histogram(df_chunks_with_md_headers, x=&#39;chunk_text_length&#39;,</span>
<span class="c1">#                    title=&#39;Histogram of Chunk Text Length&#39;, nbins=80, marginal=&#39;box&#39;)</span>
<span class="c1"># fig.show()</span>
</pre></div>
</div>
</div>
</div>
<p><img alt="image.png" src="_images/md_header_text_splitter_histogram.png" /></p>
<div class="admonition note">
<p class="admonition-title">Note</p>
<p>In the interest of time, we have already chunked the data from Solution Ops repo using Markdown Header Text Splitter approach. The result can be found at <a class="reference download internal" download="" href="_downloads/cfbef1c1e8ba04b16d47666cd0da557c/md-header-text-splitter-engineering-mlops.json"><span class="xref download myst">md-header-text-splitter-engineering-mlops.json</span></a></p>
</div>
</section>
</section>
<section id="markdown-text-splitter-using-tiktoken-encoder">
<h2>2. Markdown Text Splitter using tiktoken encoder<a class="headerlink" href="#markdown-text-splitter-using-tiktoken-encoder" title="Link to this heading">#</a></h2>
<section id="id1">
<h3>Overview<a class="headerlink" href="#id1" title="Link to this heading">#</a></h3>
<p>To decide the length of each chunk, we will look at the distribution of the document lengths and the distribution of the chunk lengths. We will then decide on a chunk length that will give us a good distribution of chunk lengths. We will use a splitter that uses the tiktoken tokenizer to split the documents into chunks. Hence we do the following:</p>
<ol class="arabic simple">
<li><p>Tokenize all the documents, and look at the distribution of the document lengths</p></li>
<li><p>Based on the above distribution, decide on a chunk length</p></li>
<li><p>Split the documents into chunks of the decided length using MarkdownTextSplitter.from_tiktoken_encoder()</p></li>
</ol>
</section>
<section id="id2">
<h3>Example<a class="headerlink" href="#id2" title="Link to this heading">#</a></h3>
<p>Let’s load LangChain’s <code class="docutils literal notranslate"><span class="pre">MarkdownTextSplitter</span></code> to split the text for us</p>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="kn">from</span> <span class="nn">langchain.text_splitter</span> <span class="kn">import</span> <span class="n">MarkdownTextSplitter</span>
</pre></div>
</div>
</div>
</div>
<p>We can split a text via <code class="docutils literal notranslate"><span class="pre">split_text</span></code> function. Let’s take a sample text:</p>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="n">text</span> <span class="o">=</span> <span class="s2">&quot;This is the text I would like to chunk up. It is the example text for this exercise&quot;</span>
</pre></div>
</div>
</div>
</div>
<p>Let’s load up the text splitted. You need to specify the <code class="docutils literal notranslate"><span class="pre">chunk</span> <span class="pre">overlap</span></code> and <code class="docutils literal notranslate"><span class="pre">chunk</span> <span class="pre">size</span></code></p>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="n">chunk_size</span> <span class="o">=</span> <span class="mi">5</span>
<span class="n">chunk_overlap</span> <span class="o">=</span> <span class="mi">3</span>
<span class="n">markdown_splitter</span> <span class="o">=</span> <span class="n">MarkdownTextSplitter</span><span class="o">.</span><span class="n">from_tiktoken_encoder</span><span class="p">(</span>
    <span class="n">chunk_size</span><span class="o">=</span><span class="n">chunk_size</span><span class="p">,</span> <span class="n">chunk_overlap</span><span class="o">=</span><span class="n">chunk_overlap</span><span class="p">)</span>
</pre></div>
</div>
</div>
</div>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="n">text</span> <span class="o">=</span> <span class="s2">&quot;This is the text I would like to chunk up. It is the example text for this exercise&quot;</span>
</pre></div>
</div>
</div>
</div>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="n">current_chunks_text_list</span> <span class="o">=</span> <span class="n">markdown_splitter</span><span class="o">.</span><span class="n">split_text</span><span class="p">(</span><span class="n">text</span><span class="p">)</span>
<span class="n">current_chunks_text_list</span>
</pre></div>
</div>
</div>
<div class="cell_output docutils container">
<div class="output text_plain highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>[&#39;This is the text I&#39;,
 &#39;the text I would like&#39;,
 &#39;I would like to chunk&#39;,
 &#39;like to chunk up.&#39;,
 &#39;chunk up. It is&#39;,
 &#39;It is the example text&#39;,
 &#39;the example text for this&#39;,
 &#39;text for this exercise&#39;]
</pre></div>
</div>
</div>
</div>
</section>
<section id="id3">
<h3>Chunk the data<a class="headerlink" href="#id3" title="Link to this heading">#</a></h3>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="kn">import</span> <span class="nn">ntpath</span>
<span class="k">def</span> <span class="nf">load_md_documents_from_folder</span><span class="p">(</span><span class="n">path</span><span class="p">:</span> <span class="nb">str</span><span class="p">)</span> <span class="o">-&gt;</span> <span class="nb">list</span><span class="p">[</span><span class="nb">str</span><span class="p">]:</span>
    <span class="nb">print</span><span class="p">(</span><span class="s2">&quot;Loading documents...&quot;</span><span class="p">)</span>
    <span class="n">data_documents</span> <span class="o">=</span> <span class="p">{</span>
        <span class="s2">&quot;solutionops_section&quot;</span><span class="p">:</span> <span class="p">[],</span>
        <span class="s2">&quot;document_object&quot;</span><span class="p">:</span> <span class="p">[],</span>
        <span class="s2">&quot;document_text&quot;</span><span class="p">:</span> <span class="p">[],</span>
        <span class="s2">&quot;document_length&quot;</span><span class="p">:</span> <span class="p">[],</span>
        <span class="s2">&quot;document_path&quot;</span><span class="p">:</span> <span class="p">[]</span>
    <span class="p">}</span>

    <span class="k">for</span> <span class="n">path</span> <span class="ow">in</span> <span class="n">paths</span><span class="p">:</span>
        <span class="k">for</span> <span class="n">file</span> <span class="ow">in</span> <span class="n">glob</span><span class="o">.</span><span class="n">glob</span><span class="p">(</span><span class="n">path</span><span class="p">,</span> <span class="n">recursive</span><span class="o">=</span><span class="kc">True</span><span class="p">):</span>
            <span class="n">loader</span> <span class="o">=</span> <span class="n">UnstructuredFileLoader</span><span class="p">(</span><span class="n">file</span><span class="p">)</span>
            <span class="n">document</span> <span class="o">=</span> <span class="n">loader</span><span class="o">.</span><span class="n">load</span><span class="p">()</span>
            <span class="n">data_documents</span><span class="p">[</span><span class="s2">&quot;solutionops_section&quot;</span><span class="p">]</span><span class="o">.</span><span class="n">append</span><span class="p">(</span><span class="n">ntpath</span><span class="o">.</span><span class="n">normpath</span><span class="p">(</span><span class="n">file</span><span class="p">)</span><span class="o">.</span><span class="n">split</span><span class="p">(</span><span class="s2">&quot;</span><span class="se">\\</span><span class="s2">&quot;</span><span class="p">)[</span><span class="mi">3</span><span class="p">])</span>
            <span class="n">data_documents</span><span class="p">[</span><span class="s2">&quot;document_object&quot;</span><span class="p">]</span><span class="o">.</span><span class="n">append</span><span class="p">(</span><span class="n">document</span><span class="p">)</span>
            <span class="n">data_documents</span><span class="p">[</span><span class="s2">&quot;document_text&quot;</span><span class="p">]</span><span class="o">.</span><span class="n">append</span><span class="p">(</span><span class="n">document</span><span class="p">[</span><span class="mi">0</span><span class="p">]</span><span class="o">.</span><span class="n">page_content</span><span class="p">)</span>
            <span class="n">data_documents</span><span class="p">[</span><span class="s2">&quot;document_length&quot;</span><span class="p">]</span><span class="o">.</span><span class="n">append</span><span class="p">(</span>
                <span class="nb">len</span><span class="p">(</span><span class="n">document</span><span class="p">[</span><span class="mi">0</span><span class="p">]</span><span class="o">.</span><span class="n">page_content</span><span class="o">.</span><span class="n">split</span><span class="p">()))</span>
            <span class="n">data_documents</span><span class="p">[</span><span class="s2">&quot;document_path&quot;</span><span class="p">]</span><span class="o">.</span><span class="n">append</span><span class="p">(</span><span class="n">file</span><span class="p">)</span>

        <span class="c1"># markdown_documents.append(document)</span>
    <span class="k">return</span> <span class="n">data_documents</span>
</pre></div>
</div>
</div>
</div>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="o">%%capture</span> --no-display

<span class="n">paths</span> <span class="o">=</span> <span class="p">[</span><span class="s2">&quot;../data/docs/code-with-engineering/**/*.md&quot;</span><span class="p">,</span><span class="s2">&quot;../data/docs/code-with-mlops/**/*.md&quot;</span><span class="p">]</span>

<span class="k">if</span> <span class="n">os</span><span class="o">.</span><span class="n">name</span> <span class="o">==</span> <span class="s2">&quot;nt&quot;</span><span class="p">:</span>
    <span class="n">paths</span> <span class="o">=</span> <span class="p">[</span><span class="n">ntpath</span><span class="o">.</span><span class="n">normpath</span><span class="p">(</span><span class="n">path</span><span class="p">)</span> <span class="k">for</span> <span class="n">path</span> <span class="ow">in</span> <span class="n">paths</span><span class="p">]</span>
<span class="n">markdown_documents</span> <span class="o">=</span> <span class="n">load_md_documents_from_folder</span><span class="p">(</span><span class="n">paths</span><span class="p">)</span>
</pre></div>
</div>
</div>
</div>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="n">markdown_files</span> <span class="o">=</span> <span class="n">pd</span><span class="o">.</span><span class="n">DataFrame</span><span class="p">(</span><span class="n">markdown_documents</span><span class="p">)</span>

<span class="n">markdown_files</span><span class="o">.</span><span class="n">head</span><span class="p">()</span>
</pre></div>
</div>
</div>
<div class="cell_output docutils container">
<div class="output text_html"><div>
<style scoped>
    .dataframe tbody tr th:only-of-type {
        vertical-align: middle;
    }

    .dataframe tbody tr th {
        vertical-align: top;
    }

    .dataframe thead th {
        text-align: right;
    }
</style>
<table border="1" class="dataframe">
  <thead>
    <tr style="text-align: right;">
      <th></th>
      <th>solutionops_section</th>
      <th>document_object</th>
      <th>document_text</th>
      <th>document_length</th>
      <th>document_path</th>
    </tr>
  </thead>
  <tbody>
    <tr>
      <th>0</th>
      <td>code-with-engineering</td>
      <td>[page_content='Structure of a Sprint\n\nThe pu...</td>
      <td>Structure of a Sprint\n\nThe purpose of this d...</td>
      <td>468</td>
      <td>../data/docs/code-with-engineering/SPRINT-STRU...</td>
    </tr>
    <tr>
      <th>1</th>
      <td>code-with-engineering</td>
      <td>[page_content='Who We Are\n\nOur team, ISE (In...</td>
      <td>Who We Are\n\nOur team, ISE (Industry Solution...</td>
      <td>263</td>
      <td>../data/docs/code-with-engineering/ISE.md</td>
    </tr>
    <tr>
      <th>2</th>
      <td>code-with-engineering</td>
      <td>[page_content="Engineering Fundamentals Checkl...</td>
      <td>Engineering Fundamentals Checklist\n\nThis che...</td>
      <td>793</td>
      <td>../data/docs/code-with-engineering/ENG-FUNDAME...</td>
    </tr>
    <tr>
      <th>3</th>
      <td>code-with-engineering</td>
      <td>[page_content='ISE Code-With Engineering Playb...</td>
      <td>ISE Code-With Engineering Playbook\n\nAn engin...</td>
      <td>357</td>
      <td>../data/docs/code-with-engineering/index.md</td>
    </tr>
    <tr>
      <th>4</th>
      <td>code-with-engineering</td>
      <td>[page_content="Work Item ID\n\nFor more inform...</td>
      <td>Work Item ID\n\nFor more information about how...</td>
      <td>325</td>
      <td>../data/docs/code-with-engineering/code-review...</td>
    </tr>
  </tbody>
</table>
</div></div></div>
</div>
<p>Let’s look at the distribution of tokens in the chunks.</p>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="kn">import</span> <span class="nn">tiktoken</span>


<span class="n">encoding</span> <span class="o">=</span> <span class="n">tiktoken</span><span class="o">.</span><span class="n">get_encoding</span><span class="p">(</span><span class="s2">&quot;cl100k_base&quot;</span><span class="p">)</span>

<span class="n">markdown_files</span><span class="p">[</span><span class="s1">&#39;tokens&#39;</span><span class="p">]</span> <span class="o">=</span> <span class="n">markdown_files</span><span class="p">[</span><span class="s1">&#39;document_text&#39;</span><span class="p">]</span><span class="o">.</span><span class="n">apply</span><span class="p">(</span>
    <span class="k">lambda</span> <span class="n">x</span><span class="p">:</span> <span class="n">encoding</span><span class="o">.</span><span class="n">encode</span><span class="p">(</span><span class="n">x</span><span class="p">))</span>
<span class="n">markdown_files</span><span class="p">[</span><span class="s1">&#39;n_tokens&#39;</span><span class="p">]</span> <span class="o">=</span> <span class="n">markdown_files</span><span class="p">[</span><span class="s1">&#39;tokens&#39;</span><span class="p">]</span><span class="o">.</span><span class="n">apply</span><span class="p">(</span>
    <span class="nb">len</span><span class="p">)</span>
</pre></div>
</div>
</div>
</div>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="c1"># fig = px.histogram(markdown_files, x=&#39;n_tokens&#39;,</span>
<span class="c1">#                    title=&#39;Distribution of tokenization lengths&#39;, nbins=80, marginal=&#39;box&#39;)</span>
<span class="c1"># fig.show()</span>
</pre></div>
</div>
</div>
</div>
<p><img alt="image.png" src="_images/md_text_splitter_tokenization_lengths.png" /></p>
<p>We decide to use chunk size = (quantile_1)/2 = 360/2 = 180 tokens. so that 75%+ of the documents will be represented by at least 2 chunks.</p>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="k">def</span> <span class="nf">create_chunks_tokens</span><span class="p">(</span><span class="n">documents</span><span class="p">:</span> <span class="nb">list</span><span class="p">)</span> <span class="o">-&gt;</span> <span class="nb">list</span><span class="p">:</span>

    <span class="n">markdown_splitter</span> <span class="o">=</span> <span class="n">MarkdownTextSplitter</span><span class="o">.</span><span class="n">from_tiktoken_encoder</span><span class="p">(</span>
        <span class="n">chunk_size</span><span class="o">=</span><span class="mi">180</span><span class="p">,</span> <span class="n">chunk_overlap</span><span class="o">=</span><span class="mi">30</span>
    <span class="p">)</span>

    <span class="n">chunk_id</span> <span class="o">=</span> <span class="mi">0</span>

    <span class="n">chunks</span> <span class="o">=</span> <span class="p">{</span>
        <span class="s2">&quot;chunkId&quot;</span><span class="p">:</span> <span class="p">[],</span>
        <span class="s2">&quot;chunkContent&quot;</span><span class="p">:</span> <span class="p">[],</span>
        <span class="s2">&quot;source&quot;</span><span class="p">:</span> <span class="p">[]</span>
    <span class="p">}</span>

    <span class="k">for</span> <span class="n">document</span> <span class="ow">in</span> <span class="n">documents</span><span class="p">:</span>
        <span class="n">current_chunks_text_list</span> <span class="o">=</span> <span class="n">markdown_splitter</span><span class="o">.</span><span class="n">split_text</span><span class="p">(</span>
            <span class="n">document</span><span class="p">[</span><span class="mi">0</span><span class="p">]</span><span class="o">.</span><span class="n">page_content</span><span class="p">)</span>
        <span class="k">for</span> <span class="n">i</span><span class="p">,</span> <span class="n">chunk</span> <span class="ow">in</span> <span class="nb">enumerate</span><span class="p">(</span><span class="n">current_chunks_text_list</span><span class="p">):</span>
            <span class="n">chunks</span><span class="p">[</span><span class="s1">&#39;chunkId&#39;</span><span class="p">]</span><span class="o">.</span><span class="n">append</span><span class="p">(</span><span class="sa">f</span><span class="s2">&quot;chunk</span><span class="si">{</span><span class="n">chunk_id</span><span class="si">}</span><span class="s2">_</span><span class="si">{</span><span class="n">i</span><span class="si">}</span><span class="s2">&quot;</span><span class="p">)</span>
            <span class="n">chunks</span><span class="p">[</span><span class="s1">&#39;chunkContent&#39;</span><span class="p">]</span><span class="o">.</span><span class="n">append</span><span class="p">(</span><span class="n">chunk</span><span class="p">)</span>
            <span class="n">chunks</span><span class="p">[</span><span class="s1">&#39;source&#39;</span><span class="p">]</span><span class="o">.</span><span class="n">append</span><span class="p">(</span><span class="n">document</span><span class="p">[</span><span class="mi">0</span><span class="p">]</span><span class="o">.</span><span class="n">metadata</span><span class="p">[</span><span class="s1">&#39;source&#39;</span><span class="p">])</span>

        <span class="n">chunk_id</span> <span class="o">+=</span> <span class="mi">1</span>
    <span class="k">return</span> <span class="n">chunks</span>
</pre></div>
</div>
</div>
</div>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="n">chunks_with_tokens</span> <span class="o">=</span> <span class="n">create_chunks_tokens</span><span class="p">(</span>
    <span class="n">markdown_files</span><span class="p">[</span><span class="s2">&quot;document_object&quot;</span><span class="p">])</span>
</pre></div>
</div>
</div>
</div>
</section>
<section id="id4">
<h3>Analysis<a class="headerlink" href="#id4" title="Link to this heading">#</a></h3>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="n">df_chunks_with_tokens</span> <span class="o">=</span> <span class="n">pd</span><span class="o">.</span><span class="n">DataFrame</span><span class="p">(</span><span class="n">chunks_with_tokens</span><span class="p">)</span>
<span class="n">df_chunks_with_tokens</span><span class="o">.</span><span class="n">head</span><span class="p">()</span>
</pre></div>
</div>
</div>
<div class="cell_output docutils container">
<div class="output text_html"><div>
<style scoped>
    .dataframe tbody tr th:only-of-type {
        vertical-align: middle;
    }

    .dataframe tbody tr th {
        vertical-align: top;
    }

    .dataframe thead th {
        text-align: right;
    }
</style>
<table border="1" class="dataframe">
  <thead>
    <tr style="text-align: right;">
      <th></th>
      <th>chunkId</th>
      <th>chunkContent</th>
      <th>source</th>
    </tr>
  </thead>
  <tbody>
    <tr>
      <th>0</th>
      <td>chunk0_0</td>
      <td>Structure of a Sprint\n\nThe purpose of this d...</td>
      <td>../data/docs/code-with-engineering/SPRINT-STRU...</td>
    </tr>
    <tr>
      <th>1</th>
      <td>chunk0_1</td>
      <td>[ ] Build a Product Backlog\n\nSet up a projec...</td>
      <td>../data/docs/code-with-engineering/SPRINT-STRU...</td>
    </tr>
    <tr>
      <th>2</th>
      <td>chunk0_2</td>
      <td>Design the first test cases\n\n[ ] Decide on b...</td>
      <td>../data/docs/code-with-engineering/SPRINT-STRU...</td>
    </tr>
    <tr>
      <th>3</th>
      <td>chunk0_3</td>
      <td>Day 3\n\n[ ] Agree on code style and on how to...</td>
      <td>../data/docs/code-with-engineering/SPRINT-STRU...</td>
    </tr>
    <tr>
      <th>4</th>
      <td>chunk0_4</td>
      <td>[ ] Agree on how to Design a feature and condu...</td>
      <td>../data/docs/code-with-engineering/SPRINT-STRU...</td>
    </tr>
  </tbody>
</table>
</div></div></div>
</div>
<p>Let’s look at the distribution of lengths in the chunks.</p>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="n">df_chunks_with_tokens</span><span class="p">[</span><span class="s1">&#39;chunk_text_length&#39;</span><span class="p">]</span> <span class="o">=</span> <span class="n">df_chunks_with_tokens</span><span class="p">[</span><span class="s1">&#39;chunkContent&#39;</span><span class="p">]</span><span class="o">.</span><span class="n">apply</span><span class="p">(</span>
    <span class="k">lambda</span> <span class="n">x</span><span class="p">:</span> <span class="nb">len</span><span class="p">(</span><span class="n">x</span><span class="o">.</span><span class="n">split</span><span class="p">()))</span>
</pre></div>
</div>
</div>
</div>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="c1"># fig = px.histogram(df_chunks_with_tokens, x=&#39;chunk_text_length&#39;,</span>
<span class="c1">#                    title=&#39;Histogram of Chunk Text Length&#39;, nbins=80, marginal=&#39;box&#39;)</span>
<span class="c1"># fig.show()</span>
</pre></div>
</div>
</div>
</div>
<p><img alt="image.png" src="_images/md_text_splitter_histogram.png" /></p>
<!-- ## 1. Fixed-sized chunking strategy

This is one of the most basic form of splitting up text. It is the process of simply dividing the text into N-character sized chunks regardless of their content or form. This method isn't recommended for any applications - but it's a great starting point for us to understand the basics. -->
<!--
**[Why Chunking Size Matters](https://blog.llamaindex.ai/evaluating-the-ideal-chunk-size-for-a-rag-system-using-llamaindex-6207e5d3fec5)**

When processing data, splitting the source documents into chunks requires care and expertise to ensure the resulting chunks are small enough to be effective during fact retrieval but not too small so that enough context is provided during summarization. The models used to generate embedding vectors have maximum limits on the text fragments provided as input. For example, the maximum length of input text for the Azure OpenAI embedding models is **8,191** tokens. Given that each token is around 4 characters of text for common OpenAI models, this maximum limit is equivalent to around 6000 words of text. If you're using these models to generate embeddings, it's critical that the input text stays under the limit. Partitioning your content into chunks ensures that your data can be processed by the Large Language Models (LLM) used for indexing and queries.

**Relevance and Granularity**: A small chunk size, like 128, yields more granular chunks. This granularity, however, presents a risk: vital information might not be among the top retrieved chunks, especially if the similarity _top_k_ setting is as restrictive as 2. Conversely, a chunk size of 512 is likely to encompass all necessary information within the top chunks, ensuring that answers to queries are readily available. To navigate this, we employ the _Faithfulness and Relevancy_ metrics. These measure the absence of ‘hallucinations’ and the ‘relevancy’ of responses based on the query and the retrieved contexts respectively.

**Response Generation Time**: As the chunk_size increases, so does the volume of information directed into the LLM to generate an answer. While this can ensure a more comprehensive context, it might also slow down the system. Ensuring that the added depth doesn't compromise the system's responsiveness is crucial.

In essence, determining the optimal chunk_size is about striking a balance: capturing all essential information without sacrificing speed. It's vital to undergo thorough testing with various sizes to find a configuration that suits the specific use case and dataset.

- **Pros**: Easy & Simple
- **Cons**: Very rigid and doesn't take into account the structure of your text

Concept to know:

- **Chunk Size** - The number of characters you would like in your chunks. 50, 100, 100,000, etc.
- **Chunk Overlap** - The amount you would like your sequential chunks to overlap. This is to try to avoid cutting a single piece of context into multiple pieces. This will create duplicate data across chunks. -->
<div class="admonition note">
<p class="admonition-title">Note</p>
<p>In the interest of time, we have already chunked the data from Solution Ops repo using Markdown Text Splitter using tiktoken encoder approach. The result can be found at <a class="reference download internal" download="" href="_downloads/a386584edd55612607aa4bbb3b7276f1/fixed-size-chunks-engineering-mlops-180-30.json"><span class="xref download myst">fixed-size-chunks-engineering-mlops-180-30.json.json</span></a></p>
</div>
<!-- In this workshop, to separate our experiments, we will take the _Full Reindex_ strategy by creating a new index -->
</section>
</section>
<section id="semantic-chunking">
<h2>3. <a class="reference external" href="https://python.langchain.com/docs/modules/data_connection/document_transformers/semantic-chunker">Semantic Chunking</a><a class="headerlink" href="#semantic-chunking" title="Link to this heading">#</a></h2>
<section id="id5">
<h3>Overview<a class="headerlink" href="#id5" title="Link to this heading">#</a></h3>
<!-- Azure: https://learn.microsoft.com/en-us/azure/ai-services/document-intelligence/concept-retrieval-augumented-generation?view=doc-intel-4.0.0#semantic-chunking) -->
<p>In the previous approach, we chose a constant value for chunk size, in a random way. We did not leverage the actual content of the document, the structure, etc. In this section, we will look at <a class="reference external" href="https://python.langchain.com/docs/modules/data_connection/document_transformers/semantic-chunker">Semantic Chunking</a> from LangChain. This approach splits the text based on semantic similarity.</p>
<p>For insights on what it is doing, you can have a look at <a class="reference external" href="https://github.com/FullStackRetrieval-com/RetrievalTutorials/blob/main/5_Levels_Of_Text_Splitting.ipynb">Level 4. Semantic Splitting</a>.</p>
</section>
<section id="id6">
<h3>Example<a class="headerlink" href="#id6" title="Link to this heading">#</a></h3>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="o">%</span><span class="k">run</span> -i ./pre-requisites.ipynb
<span class="kn">from</span> <span class="nn">langchain_openai.embeddings</span> <span class="kn">import</span> <span class="n">AzureOpenAIEmbeddings</span>
<span class="kn">from</span> <span class="nn">langchain_experimental.text_splitter</span> <span class="kn">import</span> <span class="n">SemanticChunker</span>

<span class="n">embeddings</span> <span class="o">=</span> <span class="n">AzureOpenAIEmbeddings</span><span class="p">(</span>
    <span class="n">azure_deployment</span><span class="o">=</span><span class="s2">&quot;embeddings-model&quot;</span><span class="p">,</span>
    <span class="n">openai_api_version</span><span class="o">=</span><span class="s2">&quot;2023-05-15&quot;</span><span class="p">,</span>
    <span class="n">api_key</span><span class="o">=</span><span class="n">azure_openai_key</span>
<span class="p">)</span>

<span class="k">with</span> <span class="nb">open</span><span class="p">(</span><span class="s2">&quot;../data/docs/code-with-dataops/capabilities/analytical-systems/data-ingestion/batch-stream-ingestion/index.md&quot;</span><span class="p">)</span> <span class="k">as</span> <span class="n">f</span><span class="p">:</span>
    <span class="n">state_of_the_union</span> <span class="o">=</span> <span class="n">f</span><span class="o">.</span><span class="n">read</span><span class="p">()</span>

<span class="n">text_splitter</span> <span class="o">=</span> <span class="n">SemanticChunker</span><span class="p">(</span><span class="n">embeddings</span><span class="p">)</span>

<span class="n">docs</span> <span class="o">=</span> <span class="n">text_splitter</span><span class="o">.</span><span class="n">create_documents</span><span class="p">([</span><span class="n">state_of_the_union</span><span class="p">])</span>
<span class="nb">print</span><span class="p">(</span><span class="n">docs</span><span class="p">[</span><span class="mi">1</span><span class="p">]</span><span class="o">.</span><span class="n">page_content</span><span class="p">)</span>
</pre></div>
</div>
</div>
<div class="cell_output docutils container">
<div class="output traceback highlight-ipythontb notranslate"><div class="highlight"><pre><span></span><span class="gt">---------------------------------------------------------------------------</span>
<span class="ne">AuthenticationError</span><span class="g g-Whitespace">                       </span>Traceback (most recent call last)
<span class="n">Cell</span> <span class="n">In</span><span class="p">[</span><span class="mi">27</span><span class="p">],</span> <span class="n">line</span> <span class="mi">16</span>
<span class="g g-Whitespace">     </span><span class="mi">12</span>     <span class="n">state_of_the_union</span> <span class="o">=</span> <span class="n">f</span><span class="o">.</span><span class="n">read</span><span class="p">()</span>
<span class="g g-Whitespace">     </span><span class="mi">14</span> <span class="n">text_splitter</span> <span class="o">=</span> <span class="n">SemanticChunker</span><span class="p">(</span><span class="n">embeddings</span><span class="p">)</span>
<span class="ne">---&gt; </span><span class="mi">16</span> <span class="n">docs</span> <span class="o">=</span> <span class="n">text_splitter</span><span class="o">.</span><span class="n">create_documents</span><span class="p">([</span><span class="n">state_of_the_union</span><span class="p">])</span>
<span class="g g-Whitespace">     </span><span class="mi">17</span> <span class="nb">print</span><span class="p">(</span><span class="n">docs</span><span class="p">[</span><span class="mi">1</span><span class="p">]</span><span class="o">.</span><span class="n">page_content</span><span class="p">)</span>

<span class="nn">File ~/handsontest/ai-hands-on-lab/.venv/lib/python3.9/site-packages/langchain_experimental/text_splitter.py:144,</span> in <span class="ni">SemanticChunker.create_documents</span><span class="nt">(self, texts, metadatas)</span>
<span class="g g-Whitespace">    </span><span class="mi">142</span> <span class="k">for</span> <span class="n">i</span><span class="p">,</span> <span class="n">text</span> <span class="ow">in</span> <span class="nb">enumerate</span><span class="p">(</span><span class="n">texts</span><span class="p">):</span>
<span class="g g-Whitespace">    </span><span class="mi">143</span>     <span class="n">index</span> <span class="o">=</span> <span class="o">-</span><span class="mi">1</span>
<span class="ne">--&gt; </span><span class="mi">144</span>     <span class="k">for</span> <span class="n">chunk</span> <span class="ow">in</span> <span class="bp">self</span><span class="o">.</span><span class="n">split_text</span><span class="p">(</span><span class="n">text</span><span class="p">):</span>
<span class="g g-Whitespace">    </span><span class="mi">145</span>         <span class="n">metadata</span> <span class="o">=</span> <span class="n">copy</span><span class="o">.</span><span class="n">deepcopy</span><span class="p">(</span><span class="n">_metadatas</span><span class="p">[</span><span class="n">i</span><span class="p">])</span>
<span class="g g-Whitespace">    </span><span class="mi">146</span>         <span class="k">if</span> <span class="bp">self</span><span class="o">.</span><span class="n">_add_start_index</span><span class="p">:</span>

<span class="nn">File ~/handsontest/ai-hands-on-lab/.venv/lib/python3.9/site-packages/langchain_experimental/text_splitter.py:98,</span> in <span class="ni">SemanticChunker.split_text</span><span class="nt">(self, text)</span>
<span class="g g-Whitespace">     </span><span class="mi">94</span> <span class="n">sentences</span> <span class="o">=</span> <span class="p">[</span>
<span class="nn">     95     {&quot;sentence&quot;: x, &quot;index&quot;: i} for i, x</span> in <span class="ni">enumerate</span><span class="nt">(single_sentences_list)</span>
<span class="g g-Whitespace">     </span><span class="mi">96</span> <span class="p">]</span>
<span class="g g-Whitespace">     </span><span class="mi">97</span> <span class="n">sentences</span> <span class="o">=</span> <span class="n">combine_sentences</span><span class="p">(</span><span class="n">sentences</span><span class="p">)</span>
<span class="ne">---&gt; </span><span class="mi">98</span> <span class="n">embeddings</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">embeddings</span><span class="o">.</span><span class="n">embed_documents</span><span class="p">(</span>
<span class="g g-Whitespace">     </span><span class="mi">99</span>     <span class="p">[</span><span class="n">x</span><span class="p">[</span><span class="s2">&quot;combined_sentence&quot;</span><span class="p">]</span> <span class="k">for</span> <span class="n">x</span> <span class="ow">in</span> <span class="n">sentences</span><span class="p">]</span>
<span class="g g-Whitespace">    </span><span class="mi">100</span> <span class="p">)</span>
<span class="g g-Whitespace">    </span><span class="mi">101</span> <span class="k">for</span> <span class="n">i</span><span class="p">,</span> <span class="n">sentence</span> <span class="ow">in</span> <span class="nb">enumerate</span><span class="p">(</span><span class="n">sentences</span><span class="p">):</span>
<span class="g g-Whitespace">    </span><span class="mi">102</span>     <span class="n">sentence</span><span class="p">[</span><span class="s2">&quot;combined_sentence_embedding&quot;</span><span class="p">]</span> <span class="o">=</span> <span class="n">embeddings</span><span class="p">[</span><span class="n">i</span><span class="p">]</span>

<span class="nn">File ~/handsontest/ai-hands-on-lab/.venv/lib/python3.9/site-packages/langchain_openai/embeddings/base.py:480,</span> in <span class="ni">OpenAIEmbeddings.embed_documents</span><span class="nt">(self, texts, chunk_size)</span>
<span class="g g-Whitespace">    </span><span class="mi">477</span> <span class="c1"># NOTE: to keep things simple, we assume the list may contain texts longer</span>
<span class="g g-Whitespace">    </span><span class="mi">478</span> <span class="c1">#       than the maximum context and use length-safe embedding function.</span>
<span class="g g-Whitespace">    </span><span class="mi">479</span> <span class="n">engine</span> <span class="o">=</span> <span class="n">cast</span><span class="p">(</span><span class="nb">str</span><span class="p">,</span> <span class="bp">self</span><span class="o">.</span><span class="n">deployment</span><span class="p">)</span>
<span class="ne">--&gt; </span><span class="mi">480</span> <span class="k">return</span> <span class="bp">self</span><span class="o">.</span><span class="n">_get_len_safe_embeddings</span><span class="p">(</span><span class="n">texts</span><span class="p">,</span> <span class="n">engine</span><span class="o">=</span><span class="n">engine</span><span class="p">)</span>

<span class="nn">File ~/handsontest/ai-hands-on-lab/.venv/lib/python3.9/site-packages/langchain_openai/embeddings/base.py:323,</span> in <span class="ni">OpenAIEmbeddings._get_len_safe_embeddings</span><span class="nt">(self, texts, engine, chunk_size)</span>
<span class="g g-Whitespace">    </span><span class="mi">321</span> <span class="n">batched_embeddings</span><span class="p">:</span> <span class="n">List</span><span class="p">[</span><span class="n">List</span><span class="p">[</span><span class="nb">float</span><span class="p">]]</span> <span class="o">=</span> <span class="p">[]</span>
<span class="g g-Whitespace">    </span><span class="mi">322</span> <span class="k">for</span> <span class="n">i</span> <span class="ow">in</span> <span class="n">_iter</span><span class="p">:</span>
<span class="ne">--&gt; </span><span class="mi">323</span>     <span class="n">response</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">client</span><span class="o">.</span><span class="n">create</span><span class="p">(</span>
<span class="g g-Whitespace">    </span><span class="mi">324</span>         <span class="nb">input</span><span class="o">=</span><span class="n">tokens</span><span class="p">[</span><span class="n">i</span> <span class="p">:</span> <span class="n">i</span> <span class="o">+</span> <span class="n">_chunk_size</span><span class="p">],</span> <span class="o">**</span><span class="bp">self</span><span class="o">.</span><span class="n">_invocation_params</span>
<span class="g g-Whitespace">    </span><span class="mi">325</span>     <span class="p">)</span>
<span class="g g-Whitespace">    </span><span class="mi">326</span>     <span class="k">if</span> <span class="ow">not</span> <span class="nb">isinstance</span><span class="p">(</span><span class="n">response</span><span class="p">,</span> <span class="nb">dict</span><span class="p">):</span>
<span class="g g-Whitespace">    </span><span class="mi">327</span>         <span class="n">response</span> <span class="o">=</span> <span class="n">response</span><span class="o">.</span><span class="n">dict</span><span class="p">()</span>

<span class="nn">File ~/handsontest/ai-hands-on-lab/.venv/lib/python3.9/site-packages/openai/resources/embeddings.py:113,</span> in <span class="ni">Embeddings.create</span><span class="nt">(self, input, model, dimensions, encoding_format, user, extra_headers, extra_query, extra_body, timeout)</span>
<span class="g g-Whitespace">    </span><span class="mi">107</span>         <span class="n">embedding</span><span class="o">.</span><span class="n">embedding</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">frombuffer</span><span class="p">(</span>  <span class="c1"># type: ignore[no-untyped-call]</span>
<span class="g g-Whitespace">    </span><span class="mi">108</span>             <span class="n">base64</span><span class="o">.</span><span class="n">b64decode</span><span class="p">(</span><span class="n">data</span><span class="p">),</span> <span class="n">dtype</span><span class="o">=</span><span class="s2">&quot;float32&quot;</span>
<span class="g g-Whitespace">    </span><span class="mi">109</span>         <span class="p">)</span><span class="o">.</span><span class="n">tolist</span><span class="p">()</span>
<span class="g g-Whitespace">    </span><span class="mi">111</span>     <span class="k">return</span> <span class="n">obj</span>
<span class="ne">--&gt; </span><span class="mi">113</span> <span class="k">return</span> <span class="bp">self</span><span class="o">.</span><span class="n">_post</span><span class="p">(</span>
<span class="g g-Whitespace">    </span><span class="mi">114</span>     <span class="s2">&quot;/embeddings&quot;</span><span class="p">,</span>
<span class="g g-Whitespace">    </span><span class="mi">115</span>     <span class="n">body</span><span class="o">=</span><span class="n">maybe_transform</span><span class="p">(</span><span class="n">params</span><span class="p">,</span> <span class="n">embedding_create_params</span><span class="o">.</span><span class="n">EmbeddingCreateParams</span><span class="p">),</span>
<span class="g g-Whitespace">    </span><span class="mi">116</span>     <span class="n">options</span><span class="o">=</span><span class="n">make_request_options</span><span class="p">(</span>
<span class="g g-Whitespace">    </span><span class="mi">117</span>         <span class="n">extra_headers</span><span class="o">=</span><span class="n">extra_headers</span><span class="p">,</span>
<span class="g g-Whitespace">    </span><span class="mi">118</span>         <span class="n">extra_query</span><span class="o">=</span><span class="n">extra_query</span><span class="p">,</span>
<span class="g g-Whitespace">    </span><span class="mi">119</span>         <span class="n">extra_body</span><span class="o">=</span><span class="n">extra_body</span><span class="p">,</span>
<span class="g g-Whitespace">    </span><span class="mi">120</span>         <span class="n">timeout</span><span class="o">=</span><span class="n">timeout</span><span class="p">,</span>
<span class="g g-Whitespace">    </span><span class="mi">121</span>         <span class="n">post_parser</span><span class="o">=</span><span class="n">parser</span><span class="p">,</span>
<span class="g g-Whitespace">    </span><span class="mi">122</span>     <span class="p">),</span>
<span class="g g-Whitespace">    </span><span class="mi">123</span>     <span class="n">cast_to</span><span class="o">=</span><span class="n">CreateEmbeddingResponse</span><span class="p">,</span>
<span class="g g-Whitespace">    </span><span class="mi">124</span> <span class="p">)</span>

<span class="nn">File ~/handsontest/ai-hands-on-lab/.venv/lib/python3.9/site-packages/openai/_base_client.py:1200,</span> in <span class="ni">SyncAPIClient.post</span><span class="nt">(self, path, cast_to, body, options, files, stream, stream_cls)</span>
<span class="g g-Whitespace">   </span><span class="mi">1186</span> <span class="k">def</span> <span class="nf">post</span><span class="p">(</span>
<span class="g g-Whitespace">   </span><span class="mi">1187</span>     <span class="bp">self</span><span class="p">,</span>
<span class="g g-Whitespace">   </span><span class="mi">1188</span>     <span class="n">path</span><span class="p">:</span> <span class="nb">str</span><span class="p">,</span>
   <span class="p">(</span><span class="o">...</span><span class="p">)</span>
<span class="g g-Whitespace">   </span><span class="mi">1195</span>     <span class="n">stream_cls</span><span class="p">:</span> <span class="nb">type</span><span class="p">[</span><span class="n">_StreamT</span><span class="p">]</span> <span class="o">|</span> <span class="kc">None</span> <span class="o">=</span> <span class="kc">None</span><span class="p">,</span>
<span class="g g-Whitespace">   </span><span class="mi">1196</span> <span class="p">)</span> <span class="o">-&gt;</span> <span class="n">ResponseT</span> <span class="o">|</span> <span class="n">_StreamT</span><span class="p">:</span>
<span class="g g-Whitespace">   </span><span class="mi">1197</span>     <span class="n">opts</span> <span class="o">=</span> <span class="n">FinalRequestOptions</span><span class="o">.</span><span class="n">construct</span><span class="p">(</span>
<span class="g g-Whitespace">   </span><span class="mi">1198</span>         <span class="n">method</span><span class="o">=</span><span class="s2">&quot;post&quot;</span><span class="p">,</span> <span class="n">url</span><span class="o">=</span><span class="n">path</span><span class="p">,</span> <span class="n">json_data</span><span class="o">=</span><span class="n">body</span><span class="p">,</span> <span class="n">files</span><span class="o">=</span><span class="n">to_httpx_files</span><span class="p">(</span><span class="n">files</span><span class="p">),</span> <span class="o">**</span><span class="n">options</span>
<span class="g g-Whitespace">   </span><span class="mi">1199</span>     <span class="p">)</span>
<span class="ne">-&gt; </span><span class="mi">1200</span>     <span class="k">return</span> <span class="n">cast</span><span class="p">(</span><span class="n">ResponseT</span><span class="p">,</span> <span class="bp">self</span><span class="o">.</span><span class="n">request</span><span class="p">(</span><span class="n">cast_to</span><span class="p">,</span> <span class="n">opts</span><span class="p">,</span> <span class="n">stream</span><span class="o">=</span><span class="n">stream</span><span class="p">,</span> <span class="n">stream_cls</span><span class="o">=</span><span class="n">stream_cls</span><span class="p">))</span>

<span class="nn">File ~/handsontest/ai-hands-on-lab/.venv/lib/python3.9/site-packages/openai/_base_client.py:889,</span> in <span class="ni">SyncAPIClient.request</span><span class="nt">(self, cast_to, options, remaining_retries, stream, stream_cls)</span>
<span class="g g-Whitespace">    </span><span class="mi">880</span> <span class="k">def</span> <span class="nf">request</span><span class="p">(</span>
<span class="g g-Whitespace">    </span><span class="mi">881</span>     <span class="bp">self</span><span class="p">,</span>
<span class="g g-Whitespace">    </span><span class="mi">882</span>     <span class="n">cast_to</span><span class="p">:</span> <span class="n">Type</span><span class="p">[</span><span class="n">ResponseT</span><span class="p">],</span>
   <span class="p">(</span><span class="o">...</span><span class="p">)</span>
<span class="g g-Whitespace">    </span><span class="mi">887</span>     <span class="n">stream_cls</span><span class="p">:</span> <span class="nb">type</span><span class="p">[</span><span class="n">_StreamT</span><span class="p">]</span> <span class="o">|</span> <span class="kc">None</span> <span class="o">=</span> <span class="kc">None</span><span class="p">,</span>
<span class="g g-Whitespace">    </span><span class="mi">888</span> <span class="p">)</span> <span class="o">-&gt;</span> <span class="n">ResponseT</span> <span class="o">|</span> <span class="n">_StreamT</span><span class="p">:</span>
<span class="ne">--&gt; </span><span class="mi">889</span>     <span class="k">return</span> <span class="bp">self</span><span class="o">.</span><span class="n">_request</span><span class="p">(</span>
<span class="g g-Whitespace">    </span><span class="mi">890</span>         <span class="n">cast_to</span><span class="o">=</span><span class="n">cast_to</span><span class="p">,</span>
<span class="g g-Whitespace">    </span><span class="mi">891</span>         <span class="n">options</span><span class="o">=</span><span class="n">options</span><span class="p">,</span>
<span class="g g-Whitespace">    </span><span class="mi">892</span>         <span class="n">stream</span><span class="o">=</span><span class="n">stream</span><span class="p">,</span>
<span class="g g-Whitespace">    </span><span class="mi">893</span>         <span class="n">stream_cls</span><span class="o">=</span><span class="n">stream_cls</span><span class="p">,</span>
<span class="g g-Whitespace">    </span><span class="mi">894</span>         <span class="n">remaining_retries</span><span class="o">=</span><span class="n">remaining_retries</span><span class="p">,</span>
<span class="g g-Whitespace">    </span><span class="mi">895</span>     <span class="p">)</span>

<span class="nn">File ~/handsontest/ai-hands-on-lab/.venv/lib/python3.9/site-packages/openai/_base_client.py:980,</span> in <span class="ni">SyncAPIClient._request</span><span class="nt">(self, cast_to, options, remaining_retries, stream, stream_cls)</span>
<span class="g g-Whitespace">    </span><span class="mi">977</span>         <span class="n">err</span><span class="o">.</span><span class="n">response</span><span class="o">.</span><span class="n">read</span><span class="p">()</span>
<span class="g g-Whitespace">    </span><span class="mi">979</span>     <span class="n">log</span><span class="o">.</span><span class="n">debug</span><span class="p">(</span><span class="s2">&quot;Re-raising status error&quot;</span><span class="p">)</span>
<span class="ne">--&gt; </span><span class="mi">980</span>     <span class="k">raise</span> <span class="bp">self</span><span class="o">.</span><span class="n">_make_status_error_from_response</span><span class="p">(</span><span class="n">err</span><span class="o">.</span><span class="n">response</span><span class="p">)</span> <span class="kn">from</span> <span class="kc">None</span>
<span class="g g-Whitespace">    </span><span class="mi">982</span> <span class="k">return</span> <span class="bp">self</span><span class="o">.</span><span class="n">_process_response</span><span class="p">(</span>
<span class="g g-Whitespace">    </span><span class="mi">983</span>     <span class="n">cast_to</span><span class="o">=</span><span class="n">cast_to</span><span class="p">,</span>
<span class="g g-Whitespace">    </span><span class="mi">984</span>     <span class="n">options</span><span class="o">=</span><span class="n">options</span><span class="p">,</span>
   <span class="p">(</span><span class="o">...</span><span class="p">)</span>
<span class="g g-Whitespace">    </span><span class="mi">987</span>     <span class="n">stream_cls</span><span class="o">=</span><span class="n">stream_cls</span><span class="p">,</span>
<span class="g g-Whitespace">    </span><span class="mi">988</span> <span class="p">)</span>

<span class="ne">AuthenticationError</span>: Error code: 401 - {&#39;statusCode&#39;: 401, &#39;message&#39;: &#39;Unauthorized. Access token is missing, invalid, audience is incorrect (https://cognitiveservices.azure.com), or have expired.&#39;}
</pre></div>
</div>
</div>
</div>
<div class="admonition note">
<p class="admonition-title">Note</p>
<p>In the interest of time, we have already chunked the data from Solution Ops repo using Semantic Chunking approach. The result can be found at <a class="reference download internal" download="" href="_downloads/a1835e08e7cdef66768c87b2cca335c2/semantic-chunks-engineering-mlops.json"><span class="xref download myst">semantic-chunks-engineering-mlops.json</span></a></p>
</div>
<!-- # Use the built-in skillset: [SplitSkill](https://learn.microsoft.com/en-us/azure/search/cognitive-search-skill-textsplit) -->
</section>
</section>
<section id="evaluation">
<h2>📈 Evaluation<a class="headerlink" href="#evaluation" title="Link to this heading">#</a></h2>
<p>In this workshop, to separate our experiments, we will take the <strong>Full Reindex</strong> strategy and we will create a new index per chunking strategy.</p>
<p>Therefore, for each chunking strategy we will:</p>
<ol class="arabic simple">
<li><p>Create a new index. Note: make sure to give a relevant name.</p></li>
<li><p>Embed the chunks that have been previously created. Note: In this experiment we are using AOI embedding model.</p></li>
<li><p>Populate the index with chunks.</p></li>
</ol>
<div class="admonition note">
<p class="admonition-title">Note</p>
<p>In the interest of time, we have already embedded the chunks using OAI embedding model:</p>
<ul class="simple">
<li><p>The pre-generated embeddings for Markdown Header Text Splitter can be found at <a class="reference download internal" download="" href="_downloads/d295485e187eb076b477aeb4e4dd33d7/fixed-size-chunks-180-30-engineering-mlops-ada.json"><span class="xref download myst">fixed-size-chunks-180-30-engineering-mlops-ada.json</span></a></p></li>
<li><p>The pre-generated embeddings for Markdown Text Splitter using tiktoken encode can be found at <a class="reference download internal" download="" href="_downloads/0cdbe0ef61500f2626407bc52c5886ec/md-header-text-splitter-engineering-mlops-embedded-ada.json"><span class="xref download myst">md-header-text-splitter-engineering-mlops-embedded-ada</span></a></p></li>
<li><p>The pre-generated embeddings for Semantic Chunking approach can be found at: <a class="reference internal" href="#./output/pre-generated/embeddings/./semantic-chunks-engineering-mlops-embedded-ada.json.json"><span class="xref myst">semantic-chunks-engineering-mlops-embedded-ada.json</span></a></p></li>
</ul>
</div>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="o">%%capture</span> --no-display
<span class="o">%</span><span class="n">run</span> <span class="o">-</span><span class="n">i</span> <span class="o">./</span><span class="n">helpers</span><span class="o">/</span><span class="n">search</span><span class="o">.</span><span class="n">ipynb</span>
<span class="o">%</span><span class="n">run</span> <span class="o">-</span><span class="n">i</span> <span class="o">./</span><span class="n">pre</span><span class="o">-</span><span class="n">requisites</span><span class="o">.</span><span class="n">ipynb</span>
</pre></div>
</div>
</div>
</div>
<p>Let’s load the path to each embedded chunks. Note the name of variables:</p>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="o">%</span><span class="k">run</span> -i ./pre-requisites.ipynb

<span class="nb">print</span><span class="p">(</span><span class="sa">f</span><span class="s2">&quot;Pre-generated embeddings for Markdown Header Text Splitter: </span><span class="si">{</span><span class="n">pregenerated_fixed_size_chunks_embeddings_ada</span><span class="si">}</span><span class="s2">&quot;</span><span class="p">)</span>
<span class="nb">print</span><span class="p">(</span><span class="sa">f</span><span class="s2">&quot;Pre-generated embeddings for Markdown Text Splitter using tiktoken encode: </span><span class="si">{</span><span class="n">pregenerated_markdown_header_chunks_embeddings_ada</span><span class="si">}</span><span class="s2">&quot;</span><span class="p">)</span>
<span class="nb">print</span><span class="p">(</span><span class="sa">f</span><span class="s2">&quot;Pre-generated embeddings for Semantic Chunks Splitter: </span><span class="si">{</span><span class="n">pregenerated_semantic_chunks_embeddings_ada</span><span class="si">}</span><span class="s2">&quot;</span><span class="p">)</span>
</pre></div>
</div>
</div>
<div class="cell_output docutils container">
<div class="output stream highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>Pre-generated embeddings for Markdown Header Text Splitter: ./output/pre-generated/embeddings/fixed-size-chunks-180-30-engineering-mlops-ada.json
Pre-generated embeddings for Markdown Text Splitter using tiktoken encode: ./output/pre-generated/embeddings/md-header-text-splitter-engineering-mlops-embedded-ada.json
Pre-generated embeddings for Semantic Chunks Splitter: ./output/pre-generated/embeddings/semantic-chunks-engineering-mlops-embedded-ada.json
</pre></div>
</div>
</div>
</div>
<div class="admonition note">
<p class="admonition-title">Note</p>
<p>You can reuse available functions from <a class="reference internal" href="helpers/search.html"><span class="std std-doc">./helpers/search.ipynb</span></a>, such as: <em>create_index</em> and <em>upload_data</em>.</p>
</div>
<section id="create-3-search-indexes">
<h3>Create 3 search indexes<a class="headerlink" href="#create-3-search-indexes" title="Link to this heading">#</a></h3>
<p>Sample code for creating a new index and uploading the data:</p>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="o">%</span><span class="k">run</span> -i ./helpers/search.ipynb

<span class="c1"># 1. Create the new index</span>
<span class="n">index_name</span> <span class="o">=</span> <span class="s2">&quot;fixed-size-180-30&quot;</span>
<span class="n">embedding_path</span> <span class="o">=</span> <span class="n">pregenerated_fixed_size_chunks_embeddings_ada</span>
<span class="n">create_index</span><span class="p">(</span><span class="n">index_name</span><span class="p">)</span>

<span class="c1"># Uncomment the following code when running the cell:</span>

<span class="c1"># # 3. Upload the embeddings to the new index</span>
<span class="c1"># upload_data(file_path=embedding_path, search_index_name=index_name)</span>
</pre></div>
</div>
</div>
<div class="cell_output docutils container">
<div class="output stream highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>Index: &#39;fixed-size-180-30&#39; created or updated
Uploaded 3236 documents to Index: fixed-size-180-30
</pre></div>
</div>
</div>
</div>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="o">%</span><span class="k">run</span> -i ./helpers/search.ipynb

<span class="c1"># 1. Create the new index</span>
<span class="n">index_name</span> <span class="o">=</span> <span class="s2">&quot;semantic-chunking&quot;</span>
<span class="n">embedding_path</span> <span class="o">=</span> <span class="n">pregenerated_semantic_chunks_embeddings_ada</span>
<span class="n">create_index</span><span class="p">(</span><span class="n">index_name</span><span class="p">)</span>

<span class="c1"># 3. Upload the embeddings to the new index</span>
<span class="n">upload_data</span><span class="p">(</span><span class="n">file_path</span><span class="o">=</span><span class="n">embedding_path</span><span class="p">,</span> <span class="n">search_index_name</span><span class="o">=</span><span class="n">index_name</span><span class="p">)</span>
</pre></div>
</div>
</div>
<div class="cell_output docutils container">
<div class="output stream highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>Index: &#39;semantic-chunking&#39; created or updated
Uploaded 1216 documents to Index: semantic-chunking
</pre></div>
</div>
</div>
</div>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="o">%</span><span class="k">run</span> -i ./helpers/search.ipynb

<span class="c1"># 1. Create the new index</span>
<span class="n">index_name</span> <span class="o">=</span> <span class="s2">&quot;markdown-header-chunking&quot;</span>
<span class="n">embedding_path</span> <span class="o">=</span> <span class="n">pregenerated_markdown_header_chunks_embeddings_ada</span>
<span class="n">create_index</span><span class="p">(</span><span class="n">index_name</span><span class="p">)</span>

<span class="c1"># 3. Upload the embeddings to the new index</span>
<span class="n">upload_data</span><span class="p">(</span><span class="n">file_path</span><span class="o">=</span><span class="n">embedding_path</span><span class="p">,</span> <span class="n">search_index_name</span><span class="o">=</span><span class="n">index_name</span><span class="p">)</span>
</pre></div>
</div>
</div>
</div>
</section>
<section id="evaluation-dataset">
<h3>📊 Evaluation Dataset<a class="headerlink" href="#evaluation-dataset" title="Link to this heading">#</a></h3>
<p>Note: The evaluation dataset can be found at <a class="reference download internal" download="" href="_downloads/bcdfa9bc085268b4c728951df4f5374c/qa_pairs_solutionops.json"><span class="xref download myst">solution-ops-200-qa.json</span></a>. The format is:</p>
<div class="highlight-json notranslate"><div class="highlight"><pre><span></span><span class="nt">&quot;user_prompt&quot;</span><span class="p">:</span><span class="w"> </span><span class="s2">&quot;&quot;</span><span class="p">,</span><span class="w"> </span><span class="err">#</span><span class="w"> </span><span class="err">The</span><span class="w"> </span><span class="err">ques</span><span class="kc">t</span><span class="err">io</span><span class="kc">n</span>
<span class="nt">&quot;output_prompt&quot;</span><span class="p">:</span><span class="w"> </span><span class="s2">&quot;&quot;</span><span class="p">,</span><span class="w"> </span><span class="err">#</span><span class="w"> </span><span class="err">The</span><span class="w"> </span><span class="err">a</span><span class="kc">ns</span><span class="err">wer</span>
<span class="nt">&quot;context&quot;</span><span class="p">:</span><span class="w"> </span><span class="s2">&quot;&quot;</span><span class="p">,</span><span class="w"> </span><span class="err">#</span><span class="w"> </span><span class="err">The</span><span class="w"> </span><span class="err">releva</span><span class="kc">nt</span><span class="w"> </span><span class="err">piece</span><span class="w"> </span><span class="err">o</span><span class="kc">f</span><span class="w"> </span><span class="err">i</span><span class="kc">nf</span><span class="err">orma</span><span class="kc">t</span><span class="err">io</span><span class="kc">n</span><span class="w"> </span><span class="kc">fr</span><span class="err">om</span><span class="w"> </span><span class="err">a</span><span class="w"> </span><span class="err">docume</span><span class="kc">nt</span>
<span class="nt">&quot;chunk_id&quot;</span><span class="p">:</span><span class="w"> </span><span class="s2">&quot;&quot;</span><span class="p">,</span><span class="w"> </span><span class="err">#</span><span class="w"> </span><span class="err">The</span><span class="w"> </span><span class="err">ID</span><span class="w"> </span><span class="err">o</span><span class="kc">f</span><span class="w"> </span><span class="kc">t</span><span class="err">he</span><span class="w"> </span><span class="err">chu</span><span class="kc">n</span><span class="err">k</span>
<span class="nt">&quot;source&quot;</span><span class="p">:</span><span class="w"> </span><span class="s2">&quot;&quot;</span><span class="w"> </span><span class="err">#</span><span class="w"> </span><span class="err">The</span><span class="w"> </span><span class="err">pa</span><span class="kc">t</span><span class="err">h</span><span class="w"> </span><span class="kc">t</span><span class="err">o</span><span class="w"> </span><span class="kc">t</span><span class="err">he</span><span class="w"> </span><span class="err">docume</span><span class="kc">nt</span><span class="p">,</span><span class="w"> </span><span class="err">i.e.</span><span class="w"> </span><span class="s2">&quot;..\\data\\docs\\code-with-dataops\\index.md&quot;</span>
</pre></div>
</div>
<p>Let us configure the path to evaluation dataset and reload environment variables</p>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="o">%</span><span class="k">run</span> -i ./pre-requisites.ipynb
</pre></div>
</div>
</div>
</div>
</section>
<section id="evaluation-metrics">
<h3>🎯Evaluation Metrics<a class="headerlink" href="#evaluation-metrics" title="Link to this heading">#</a></h3>
<!-- `Retrieval_evaluation` function goes through our evaluation dataset and verifies for each question if the retrieved documents include the expected document. -->
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="o">%</span><span class="k">run</span> -i ./helpers/search.ipynb

<span class="kn">from</span> <span class="nn">statistics</span> <span class="kn">import</span> <span class="n">mean</span><span class="p">,</span> <span class="n">median</span>
<span class="kn">import</span> <span class="nn">os</span>
<span class="kn">import</span> <span class="nn">numpy</span> <span class="k">as</span> <span class="nn">np</span>
<span class="kn">from</span> <span class="nn">numpy.linalg</span> <span class="kn">import</span> <span class="n">norm</span>
</pre></div>
</div>
</div>
</div>
<p>Let’s define the evaluation metrics:</p>
<ul class="simple">
<li><p>Cosine similarity: will calculate the similarity between the first retrieved chunk and the expected chunk. We will look at the average and mean cosine similarity across our evaluation dataset.</p></li>
<li><p>Accuracy: we will calculate how many times the system returned the expected document, and by document we mean the actual path to the markdown file.</p></li>
</ul>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="k">def</span> <span class="nf">calculate_cosine_similarity</span><span class="p">(</span><span class="n">expected_document_vector</span><span class="p">,</span> <span class="n">retrieved_document_vector</span><span class="p">):</span>
    <span class="n">cosine_sim</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">dot</span><span class="p">(</span><span class="n">expected_document_vector</span><span class="p">,</span> <span class="n">retrieved_document_vector</span><span class="p">)</span> <span class="o">/</span> \
        <span class="p">(</span><span class="n">norm</span><span class="p">(</span><span class="n">expected_document_vector</span><span class="p">)</span><span class="o">*</span><span class="n">norm</span><span class="p">(</span><span class="n">retrieved_document_vector</span><span class="p">))</span>
    <span class="k">return</span> <span class="nb">float</span><span class="p">(</span><span class="n">cosine_sim</span><span class="p">)</span>
</pre></div>
</div>
</div>
</div>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="kn">import</span> <span class="nn">ntpath</span>
<span class="k">def</span> <span class="nf">calculate_metrics</span><span class="p">(</span><span class="n">evaluation_data_path</span><span class="p">,</span> <span class="n">search_index_name</span><span class="p">,</span> <span class="n">embedding_function</span><span class="o">=</span><span class="n">oai_query_embedding</span><span class="p">):</span>
<span class="w">    </span><span class="sd">&quot;&quot;&quot; Evaluate the retrieval performance of the search index using the evaluation data set.</span>
<span class="sd">    Args:</span>
<span class="sd">    evaluation_data_path (str): The path to the evaluation data set.</span>
<span class="sd">    embedding_function (function): The function to use for embedding the question.</span>
<span class="sd">    search_index_name (str): The name of the search index to use for retrieval.</span>

<span class="sd">    Returns:</span>
<span class="sd">    list: The cosine similarities between the expected documents and the top retrieved documents.</span>
<span class="sd">    &quot;&quot;&quot;</span>
    <span class="k">if</span> <span class="ow">not</span> <span class="n">os</span><span class="o">.</span><span class="n">path</span><span class="o">.</span><span class="n">exists</span><span class="p">(</span><span class="n">evaluation_data_path</span><span class="p">):</span>
        <span class="nb">print</span><span class="p">(</span><span class="sa">f</span><span class="s2">&quot;The path to the evaluation data set </span><span class="si">{</span><span class="n">evaluation_data_path</span><span class="si">}</span><span class="s2"> does not exist. Please check the path and try again.&quot;</span><span class="p">)</span>
        <span class="k">return</span>
    <span class="n">nr_correctly_retrieved_documents</span> <span class="o">=</span> <span class="mi">0</span>
    <span class="n">nr_qa</span> <span class="o">=</span> <span class="mi">0</span>
    <span class="n">cosine_similarities</span> <span class="o">=</span> <span class="p">[]</span>

    <span class="k">with</span> <span class="nb">open</span><span class="p">(</span><span class="n">evaluation_data_path</span><span class="p">,</span> <span class="s2">&quot;r&quot;</span><span class="p">,</span> <span class="n">encoding</span><span class="o">=</span><span class="s2">&quot;utf-8&quot;</span><span class="p">)</span> <span class="k">as</span> <span class="n">file</span><span class="p">:</span>
        <span class="n">evaluation_data</span> <span class="o">=</span> <span class="n">json</span><span class="o">.</span><span class="n">load</span><span class="p">(</span><span class="n">file</span><span class="p">)</span>
        <span class="k">for</span> <span class="n">data</span> <span class="ow">in</span> <span class="n">evaluation_data</span><span class="p">:</span>
            <span class="n">user_prompt</span> <span class="o">=</span> <span class="n">data</span><span class="p">[</span><span class="s2">&quot;user_prompt&quot;</span><span class="p">]</span>
            <span class="n">expected_document</span> <span class="o">=</span> <span class="n">data</span><span class="p">[</span><span class="s2">&quot;source&quot;</span><span class="p">]</span>
            <span class="n">expected_document_vector</span> <span class="o">=</span> <span class="n">embedding_function</span><span class="p">(</span><span class="n">data</span><span class="p">[</span><span class="s2">&quot;context&quot;</span><span class="p">])</span>

            <span class="c1"># 1. Search in the index</span>
            <span class="n">search_response</span> <span class="o">=</span> <span class="n">search_documents</span><span class="p">(</span>
                <span class="n">search_index_name</span><span class="o">=</span><span class="n">search_index_name</span><span class="p">,</span>
                <span class="nb">input</span><span class="o">=</span><span class="n">user_prompt</span><span class="p">,</span>
                <span class="n">embedding_function</span><span class="o">=</span><span class="n">embedding_function</span><span class="p">,</span>
            <span class="p">)</span>

            <span class="n">retrieved_documents</span> <span class="o">=</span> <span class="p">[</span><span class="n">ntpath</span><span class="o">.</span><span class="n">normpath</span><span class="p">(</span><span class="n">response</span><span class="p">[</span><span class="s2">&quot;source&quot;</span><span class="p">])</span>
                                   <span class="k">for</span> <span class="n">response</span> <span class="ow">in</span> <span class="n">search_response</span><span class="p">]</span>
            <span class="n">top_retrieved_document</span> <span class="o">=</span> <span class="n">search_response</span><span class="p">[</span><span class="mi">0</span><span class="p">][</span><span class="s2">&quot;chunkContentVector&quot;</span><span class="p">]</span>


            <span class="c1"># 2. Calculate cosine similarity between the expected document and the top retrieved document</span>
            <span class="n">cosine_similarity</span> <span class="o">=</span> <span class="n">calculate_cosine_similarity</span><span class="p">(</span>
                <span class="n">expected_document_vector</span><span class="p">,</span> <span class="n">top_retrieved_document</span><span class="p">)</span>
            <span class="n">cosine_similarities</span><span class="o">.</span><span class="n">append</span><span class="p">(</span><span class="n">cosine_similarity</span><span class="p">)</span>

            <span class="c1"># 3. If the expected document is part of the retrieved documents,</span>
            <span class="c1"># we will consider it correctly retrieved</span>
            <span class="k">if</span> <span class="n">ntpath</span><span class="o">.</span><span class="n">normpath</span><span class="p">(</span><span class="n">expected_document</span><span class="p">)</span> <span class="ow">in</span> <span class="n">retrieved_documents</span><span class="p">:</span>
                <span class="n">nr_correctly_retrieved_documents</span> <span class="o">+=</span> <span class="mi">1</span>
            <span class="n">nr_qa</span> <span class="o">+=</span> <span class="mi">1</span>
    <span class="n">accuracy</span> <span class="o">=</span> <span class="p">(</span><span class="n">nr_correctly_retrieved_documents</span> <span class="o">/</span> <span class="n">nr_qa</span><span class="p">)</span><span class="o">*</span><span class="mi">100</span>
    <span class="nb">print</span><span class="p">(</span><span class="sa">f</span><span class="s2">&quot;Accuracy: </span><span class="si">{</span><span class="n">accuracy</span><span class="si">}</span><span class="s2">% of the documents were correctly retrieved from Index </span><span class="si">{</span><span class="n">index_name</span><span class="si">}</span><span class="s2">.&quot;</span><span class="p">)</span>

    <span class="k">return</span> <span class="n">cosine_similarities</span>
</pre></div>
</div>
</div>
</div>
</section>
<section id="evaluate-the-markdown-header-text-splitter-took-3-min">
<h3>👩‍💻 1. Evaluate the Markdown Header Text Splitter - took 3 min<a class="headerlink" href="#evaluate-the-markdown-header-text-splitter-took-3-min" title="Link to this heading">#</a></h3>
<details markdown="1">
<summary> 🔍 Code. It may take up to 3 minutes: </summary>
<div class="highlight-python notranslate"><div class="highlight"><pre><span></span>
<span class="c1"># TODO: Replace this with the name of the index you want to evaluate</span>
<span class="n">index_name</span> <span class="o">=</span> <span class="s2">&quot;markdown-header-chunking&quot;</span>

<span class="n">cosine_similarities</span> <span class="o">=</span> <span class="n">calculate_metrics</span><span class="p">(</span>
    <span class="n">evaluation_data_path</span><span class="o">=</span><span class="n">path_to_evaulation_dataset</span><span class="p">,</span>
    <span class="n">search_index_name</span><span class="o">=</span><span class="n">index_name</span><span class="p">,</span>
<span class="p">)</span>

<span class="n">avg_score</span> <span class="o">=</span> <span class="n">mean</span><span class="p">(</span><span class="n">cosine_similarities</span><span class="p">)</span>
<span class="nb">print</span><span class="p">(</span><span class="sa">f</span><span class="s2">&quot;Avg score:</span><span class="si">{</span><span class="n">avg_score</span><span class="si">}</span><span class="s2">&quot;</span><span class="p">)</span>
<span class="n">median_score</span> <span class="o">=</span> <span class="n">median</span><span class="p">(</span><span class="n">cosine_similarities</span><span class="p">)</span>
<span class="nb">print</span><span class="p">(</span><span class="sa">f</span><span class="s2">&quot;Median score: </span><span class="si">{</span><span class="n">median_score</span><span class="si">}</span><span class="s2">&quot;</span><span class="p">)</span>
</pre></div>
</div>
</details>
<!-- - Accuracy: 28.999999999999996% of the documents were correctly retrieved from Index markdwon-header-chunkig.

- Avg cosine score:0.8077330619452607

- Median cosine score: 0.8036465351518314 -->
</section>
<section id="evaluate-the-markdown-text-splitter-using-tiktoken-encode">
<h3>👩‍💻 2. Evaluate the Markdown Text Splitter using tiktoken encode<a class="headerlink" href="#evaluate-the-markdown-text-splitter-using-tiktoken-encode" title="Link to this heading">#</a></h3>
<p>Note: It’s equivalent to the first experiment.</p>
<details markdown="1">
<summary> 🔍 Code. It may take up to 3 minutes: </summary>
<div class="highlight-python notranslate"><div class="highlight"><pre><span></span>
<span class="c1"># TODO: Replace this with the name of the index you want to evaluate</span>
<span class="n">index_name</span> <span class="o">=</span> <span class="s2">&quot;fixed-size-180-30&quot;</span>

<span class="n">cosine_similarities</span> <span class="o">=</span> <span class="n">calculate_metrics</span><span class="p">(</span>
    <span class="n">evaluation_data_path</span><span class="o">=</span><span class="n">path_to_evaulation_dataset</span><span class="p">,</span>
    <span class="n">search_index_name</span><span class="o">=</span><span class="n">index_name</span><span class="p">,</span>
<span class="p">)</span>

<span class="n">avg_score</span> <span class="o">=</span> <span class="n">mean</span><span class="p">(</span><span class="n">cosine_similarities</span><span class="p">)</span>
<span class="nb">print</span><span class="p">(</span><span class="sa">f</span><span class="s2">&quot;Avg score:</span><span class="si">{</span><span class="n">avg_score</span><span class="si">}</span><span class="s2">&quot;</span><span class="p">)</span>
<span class="n">median_score</span> <span class="o">=</span> <span class="n">median</span><span class="p">(</span><span class="n">cosine_similarities</span><span class="p">)</span>
<span class="nb">print</span><span class="p">(</span><span class="sa">f</span><span class="s2">&quot;Median score: </span><span class="si">{</span><span class="n">median_score</span><span class="si">}</span><span class="s2">&quot;</span><span class="p">)</span>
</pre></div>
</div>
</details>
</section>
<section id="evaluate-the-semantic-chunking-strategy">
<h3>👩‍💻 3. Evaluate the semantic chunking strategy<a class="headerlink" href="#evaluate-the-semantic-chunking-strategy" title="Link to this heading">#</a></h3>
<!--
- Accuracy: 70.33333333333334% of the documents were correctly retrieved from Index semantic-chunking.
- Avg score:0.8640008644417442
- Median score: 0.8739910472047012 -->
<details markdown="1">
<summary> 🔍 Code. It may take up to 3 minutes: </summary>
<div class="highlight-python notranslate"><div class="highlight"><pre><span></span>
<span class="c1"># TODO: Replace this with the name of the index you want to evaluate</span>
<span class="n">index_name</span> <span class="o">=</span> <span class="s2">&quot;semantic-chunking&quot;</span>

<span class="n">cosine_similarities</span> <span class="o">=</span> <span class="n">calculate_metrics</span><span class="p">(</span>
    <span class="n">evaluation_data_path</span><span class="o">=</span><span class="n">path_to_evaulation_dataset</span><span class="p">,</span>
    <span class="n">search_index_name</span><span class="o">=</span><span class="n">index_name</span><span class="p">,</span>
<span class="p">)</span>

<span class="n">avg_score</span> <span class="o">=</span> <span class="n">mean</span><span class="p">(</span><span class="n">cosine_similarities</span><span class="p">)</span>
<span class="nb">print</span><span class="p">(</span><span class="sa">f</span><span class="s2">&quot;Avg score:</span><span class="si">{</span><span class="n">avg_score</span><span class="si">}</span><span class="s2">&quot;</span><span class="p">)</span>
<span class="n">median_score</span> <span class="o">=</span> <span class="n">median</span><span class="p">(</span><span class="n">cosine_similarities</span><span class="p">)</span>
<span class="nb">print</span><span class="p">(</span><span class="sa">f</span><span class="s2">&quot;Median score: </span><span class="si">{</span><span class="n">median_score</span><span class="si">}</span><span class="s2">&quot;</span><span class="p">)</span>
</pre></div>
</div>
</details>
</section>
</section>
<section id="conclusions">
<h2>💡 Conclusions<a class="headerlink" href="#conclusions" title="Link to this heading">#</a></h2>
<p>Take few moments to analyse the results.</p>
<details markdown="1">
<summary> 🔍 Pre-calculated results: </summary>
<p><img alt="results.png" src="_images/chunking-results.png" /></p>
<p>In terms of cosine similiraty, all strategies got a good score. However, the “Markdown Text splitter” got the highest one.  In terms of accuracy, the markdown header text splitter is falling behind with only 63% accuracy. The Semantic chunker has a reasonable accuracy of 70%, but is far behind the “Markdown text splitter” one. That is a surprising result, as intuitively, we would have expected the semantic chunking strategy got the highest score.</p>
<p>In reality, the results of “Markdown Text splitter” are better than it probably is in practice. Can you guess why?</p>
<p>…
In practice, the evaluation dataset is ideally created and curated by subject-matter human experts. In this workshop, we have created synthetic data … using the markdown text splitter chunking strategy, so the results above are inherently biased. If one were to regenerate the data, one should consider to create question/answer pairs on a whole document rather than chunking every document.</p>
</details>
</section>
</section>

    <script type="text/x-thebe-config">
    {
        requestKernel: true,
        binderOptions: {
            repo: "binder-examples/jupyter-stacks-datascience",
            ref: "master",
        },
        codeMirrorConfig: {
            theme: "abcdef",
            mode: "python"
        },
        kernelOptions: {
            name: "python3",
            path: "./."
        },
        predefinedOutput: true
    }
    </script>
    <script>kernelName = 'python3'</script>

                </article>
              

              
              
              
              
                <footer class="prev-next-footer">
                  
<div class="prev-next-area">
    <a class="left-prev"
       href="3.1.experiment_embedding.html"
       title="previous page">
      <i class="fa-solid fa-angle-left"></i>
      <div class="prev-next-info">
        <p class="prev-next-subtitle">previous</p>
        <p class="prev-next-title">3.1. Embeddings Experiment</p>
      </div>
    </a>
    <a class="right-next"
       href="3.3.end_to_end_evaluation.html"
       title="next page">
      <div class="prev-next-info">
        <p class="prev-next-subtitle">next</p>
        <p class="prev-next-title">3.3. End-to-end evaluation</p>
      </div>
      <i class="fa-solid fa-angle-right"></i>
    </a>
</div>
                </footer>
              
            </div>
            
            
              
                <div class="bd-sidebar-secondary bd-toc"><div class="sidebar-secondary-items sidebar-secondary__inner">


  <div class="sidebar-secondary-item">
  <div class="page-toc tocsection onthispage">
    <i class="fa-solid fa-list"></i> Contents
  </div>
  <nav class="bd-toc-nav page-toc">
    <ul class="visible nav section-nav flex-column">
<li class="toc-h2 nav-item toc-entry"><a class="reference internal nav-link" href="#experiment-overview">Experiment Overview</a></li>
<li class="toc-h2 nav-item toc-entry"><a class="reference internal nav-link" href="#why-does-chunking-matter">Why does chunking matter?</a></li>
<li class="toc-h2 nav-item toc-entry"><a class="reference internal nav-link" href="#setup">Setup</a></li>
<li class="toc-h2 nav-item toc-entry"><a class="reference internal nav-link" href="#markdown-header-text-splitter">1. Markdown Header Text Splitter</a><ul class="nav section-nav flex-column">
<li class="toc-h3 nav-item toc-entry"><a class="reference internal nav-link" href="#overview">Overview</a></li>
<li class="toc-h3 nav-item toc-entry"><a class="reference internal nav-link" href="#example">Example</a></li>
<li class="toc-h3 nav-item toc-entry"><a class="reference internal nav-link" href="#chunk-the-data">Chunk the data</a></li>
<li class="toc-h3 nav-item toc-entry"><a class="reference internal nav-link" href="#analysis">Analysis</a></li>
</ul>
</li>
<li class="toc-h2 nav-item toc-entry"><a class="reference internal nav-link" href="#markdown-text-splitter-using-tiktoken-encoder">2. Markdown Text Splitter using tiktoken encoder</a><ul class="nav section-nav flex-column">
<li class="toc-h3 nav-item toc-entry"><a class="reference internal nav-link" href="#id1">Overview</a></li>
<li class="toc-h3 nav-item toc-entry"><a class="reference internal nav-link" href="#id2">Example</a></li>
<li class="toc-h3 nav-item toc-entry"><a class="reference internal nav-link" href="#id3">Chunk the data</a></li>
<li class="toc-h3 nav-item toc-entry"><a class="reference internal nav-link" href="#id4">Analysis</a></li>
</ul>
</li>
<li class="toc-h2 nav-item toc-entry"><a class="reference internal nav-link" href="#semantic-chunking">3. Semantic Chunking</a><ul class="nav section-nav flex-column">
<li class="toc-h3 nav-item toc-entry"><a class="reference internal nav-link" href="#id5">Overview</a></li>
<li class="toc-h3 nav-item toc-entry"><a class="reference internal nav-link" href="#id6">Example</a></li>
</ul>
</li>
<li class="toc-h2 nav-item toc-entry"><a class="reference internal nav-link" href="#evaluation">📈 Evaluation</a><ul class="nav section-nav flex-column">
<li class="toc-h3 nav-item toc-entry"><a class="reference internal nav-link" href="#create-3-search-indexes">Create 3 search indexes</a></li>
<li class="toc-h3 nav-item toc-entry"><a class="reference internal nav-link" href="#evaluation-dataset">📊 Evaluation Dataset</a></li>
<li class="toc-h3 nav-item toc-entry"><a class="reference internal nav-link" href="#evaluation-metrics">🎯Evaluation Metrics</a></li>
<li class="toc-h3 nav-item toc-entry"><a class="reference internal nav-link" href="#evaluate-the-markdown-header-text-splitter-took-3-min">👩‍💻 1. Evaluate the Markdown Header Text Splitter - took 3 min</a></li>
<li class="toc-h3 nav-item toc-entry"><a class="reference internal nav-link" href="#evaluate-the-markdown-text-splitter-using-tiktoken-encode">👩‍💻 2. Evaluate the Markdown Text Splitter using tiktoken encode</a></li>
<li class="toc-h3 nav-item toc-entry"><a class="reference internal nav-link" href="#evaluate-the-semantic-chunking-strategy">👩‍💻 3. Evaluate the semantic chunking strategy</a></li>
</ul>
</li>
<li class="toc-h2 nav-item toc-entry"><a class="reference internal nav-link" href="#conclusions">💡 Conclusions</a></li>
</ul>
  </nav></div>

</div></div>
              
            
          </div>
          <footer class="bd-footer-content">
            
<div class="bd-footer-content__inner container">
  
  <div class="footer-item">
    
<p class="component-author">
By Raouf Aliouat & Adina Stoll
</p>

  </div>
  
  <div class="footer-item">
    

  <p class="copyright">
    
      © Copyright 2023.
      <br/>
    
  </p>

  </div>
  
  <div class="footer-item">
    
  </div>
  
  <div class="footer-item">
    
  </div>
  
</div>
          </footer>
        

      </main>
    </div>
  </div>
  
  <!-- Scripts loaded after <body> so the DOM is not blocked -->
  <script src="_static/scripts/bootstrap.js?digest=8d27b9dea8ad943066ae"></script>
<script src="_static/scripts/pydata-sphinx-theme.js?digest=8d27b9dea8ad943066ae"></script>

  <footer class="bd-footer">
  </footer>
  </body>
</html>