# Welcome

Retrieval Augmented Generation (RAG) Applications, based on Large Language Models (LLMs), are a new breed of application. The architecture has become increasingly important and is currently at the core of many engagements. 
<!-- In this workshop, you will go through the core aspects and considerations one should take when working on RAG based GenAI Solutions. -->
## Goal
During this workshop, we will leverage each other's knowledge and will look at: 
- **Pre-production**: how to experiment, evaluate and come up with the best RAG-based solution for a given use case.
- **Post-production**: after deploying the solution to production, how to monitor and ensure that *it works as expected*. Oh wait, what does that even mean?

Through this workshop, we aim to:
- speed up the onboarding process on this topic
- provide a framework that would guide you in your thought process when building such applications
- last, but not least, HAVE FUN!
<!-- - capture key best practices that have already been established in the industry -->


<!-- ## Content:
```{tableofcontents}
``` -->

## Ready? Let's start!
![intro](./images/workshop.jpg)


```{seealso}
- RAG Experiment Accelerator: https://github.com/microsoft/rag-experiment-accelerator/tree/development
- End-to-End RAG Pattern with OpenAI: https://github.com/microsoft/rag-openai/tree/main
- Vector samples - Azure AI Search: https://github.com/Azure/azure-search-vector-samples/tree/main
```


