{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 3.2. Embeddings\n",
    "\n",
    "According to [multiple estimates](https://mitsloan.mit.edu/ideas-made-to-matter/tapping-power-unstructured-data), 80% of data generated by businesses today is unstructured data such as text, images, or audio. This data has enormous potential for machine learning applications, but there is _some_ work to be done before it can be used directly.\n",
    "\n",
    "Embeddings are the backbone of our system. Our goal is to understand how different embeddings or ways of using embeddings impact relevancy of the returned results for a given query.\n",
    "\n",
    "üìù**Hypothesis**\n",
    "\n",
    "The hypothesis for this experiment is an exploratory one: \"Can introducing a new word embedding method improve the system's performance?\"\n",
    "\n",
    "üéØ **Measure of Success**\n",
    "\n",
    "As we highlighted in the `Chapter 3. Experiments`, our system has two components: the retrieval and the generative one. Take a moment to think what would be the part that would be impacted if we change the embedding model?\n",
    "\n",
    "<details markdown=\"1\">\n",
    "<summary> Hint:</summary>\n",
    "\n",
    "Well, embeddings are used for transforming the input query from plain text into a vector, as well as for vectorizing the documents we have in our index. Therefore, it contributes to how well the system can retrieve relevant documents based on the input query and the documents. In other words, the retrieval component.\n",
    "\n",
    "</details>\n",
    "\n",
    "<!-- <details markdown=\"1\">\n",
    "<summary> Here‚Äôs how to connect to your AKS cluster:</summary>\n",
    "\n",
    "```sh\n",
    "AKS_NAME=$(az aks list -g \"$ENV_RESOURCE_GROUP_NAME\" --query \"[0].name\" -o tsv)\n",
    "az aks get-credentials \\\n",
    "--resource-group \"$ENV_RESOURCE_GROUP_NAME\" \\\n",
    "--name \"$AKS_NAME\"\n",
    "```\n",
    "\n",
    "</details> -->\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## üëÄ Get to know the data\n",
    "\n",
    "Before we try out different embedding models, let's first try to understand the data. In what follows, you will see the data being clustered and keywords extracted from each cluster. To accomplish this, we performed Dimensionality Reduction, using [t-SNE](https://towardsdatascience.com/what-why-and-how-of-t-sne-1f78d13e224d). If you want to see the code we've been using to accomplish this, go to [t-SNE.ipynb](./helpers/t-SNE.ipynb). Note: in this experiment, we work with the dataset found at `chunks-solution-ops-200-300-0`\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%run -i ./helpers/t-SNE.ipynb"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "```{note}\n",
    "\n",
    "```\n",
    "\n",
    "As we have seen from the cluster from above, the data `can` be clustered, and the clusters seem to be different from one another. One is centered on data (sql, databricks) vs backlog related (stories, sprint, team) vs engineering fundamentals (security, testing, code). However, if we think about these clusters on a broader sense, they are part of one big cluster, which is IT.\n",
    "\n",
    "## Which Embeddings Model to use?\n",
    "\n",
    "There are several embedding options:\n",
    "\n",
    "- OpenAI models, such as: [`text-embedding-ada-002`](https://platform.openai.com/docs/guides/embeddings/what-are-embeddings), `text-embedding-3-small`, `text-embedding-3-large`\n",
    "- HuggingFace models, which offers a wide range of models. The [MTEB Leaderboard](https://huggingface.co/spaces/mteb/leaderboard) ranks the performance of embeddings models on a few axis, though not all models can be run locally.\n",
    "\n",
    "### a) Embed a query using an embedding model from OpenAI\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import dotenv\n",
    "\n",
    "%reload_ext dotenv\n",
    "%dotenv\n",
    "\n",
    "aoai_endpoint = os.environ[\"aoai_endpoint\"]\n",
    "aoi_api_key = os.environ[\"aoi_api_key\"]\n",
    "embedding_model_name = os.environ[\"embeddingModelName\"]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import requests\n",
    "\n",
    "\n",
    "def get_query_embedding(\n",
    "    query,\n",
    "    endpoint=aoai_endpoint,\n",
    "    api_key=aoi_api_key,\n",
    "    api_version=\"2023-07-01-preview\",\n",
    "    embedding_model_deployment=embedding_model_name,\n",
    "):\n",
    "    request_url = f\"{endpoint}/openai/deployments/{embedding_model_deployment}/embeddings?api-version={api_version}\"\n",
    "    headers = {\"Content-Type\": \"application/json\", \"api-key\": api_key}\n",
    "    request_payload = {\"input\": query}\n",
    "    embedding_response = requests.post(\n",
    "        request_url, json=request_payload, headers=headers, timeout=None\n",
    "    )\n",
    "    if embedding_response.status_code == 200:\n",
    "        data_values = embedding_response.json()[\"data\"]\n",
    "        embeddings_vectors = [data_value[\"embedding\"] for data_value in data_values]\n",
    "        return embeddings_vectors\n",
    "    else:\n",
    "        raise Exception(f\"failed to get embedding: {embedding_response.json()}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### See the embedded result for one query\n",
    "\n",
    "Feel free to update the `query` variable\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "query = \"Hello\"\n",
    "\n",
    "query_vectors = get_query_embedding(\n",
    "    query, aoai_endpoint, aoi_api_key, \"2023-07-01-preview\", embedding_model_name\n",
    ")\n",
    "\n",
    "print(f\"The embedded vector is: {query_vectors[0]}\")\n",
    "print(f\"The length of the embedding is: {len(query_vectors[0])}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Embed the chunks and save to a file\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def generate_embeddings_for_chunks(totalNumberOfDocuments):\n",
    "    path_to_file = f\"./output/chunks-solution-ops-embedded-{totalNumberOfDocuments}.json\"\n",
    "    if(os.path.exists(path_to_file)):\n",
    "        print(f\"Embeddings were already created for chunked data at: {path_to_file} \")\n",
    "        return\n",
    "    with open(f\"./output/chunks-solution-ops-{totalNumberOfDocuments}.json\", \"r\", encoding=\"utf-8\") as file:\n",
    "        input_data = json.load(file)\n",
    "        for chunk in input_data:\n",
    "            content = chunk[\"chunkContent\"]\n",
    "            content_emebddings = get_query_embedding(content)[0]\n",
    "            chunk[\"chunkContentVector\"] = content_emebddings\n",
    "    print(f\"Created {len(input_data)} chunks\")\n",
    "    print(f\"Example of one chunk: {input_data[1]}\")\n",
    "\n",
    "    with open(\"./output/chunks-solution-ops-embedded-{totalNumberOfDocuments}.json\", \"w\") as f:\n",
    "        json.dump(input_data, f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "totalNumberOfDocuments = 200\n",
    "generate_embeddings_for_chunks(totalNumberOfDocuments)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### b) Embed a query using an embedding model from Hugging Face\n",
    "\n",
    "We will use [`infloat/e5-small-v2`](https://huggingface.co/intfloat/e5-small-v2) from Hugging Face, which is of size 0.13 GB.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sentence_transformers import SentenceTransformer\n",
    "\n",
    "model = SentenceTransformer(\"intfloat/e5-small-v2\")\n",
    "query = \"Hello\"\n",
    "\n",
    "embedded_query = model.encode(query, normalize_embeddings=True)\n",
    "print(len(embedded_query))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sentence_transformers import SentenceTransformer\n",
    "\n",
    "model = SentenceTransformer(\"intfloat/e5-small-v2\")\n",
    "\n",
    "with open(\"./data/text-sample.json\", \"r\", encoding=\"utf-8\") as file:\n",
    "    input_data = json.load(file)\n",
    "\n",
    "for item in input_data:\n",
    "    title = item[\"title\"]\n",
    "    content = item[\"content\"]\n",
    "    title_embeddings = model.encode(title, normalize_embeddings=True)\n",
    "    content_embeddings = model.encode(content, normalize_embeddings=True)\n",
    "    item[\"titleVector\"] = title_embeddings.tolist()\n",
    "    item[\"contentVector\"] = content_embeddings.tolist()\n",
    "\n",
    "with open(\"./output/docVectors-e5.json\", \"w\") as f:\n",
    "    json.dump(input_data, f)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
