{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 3.3 Search\n",
    "\n",
    "Search is at the core of the RAG pattern. Precise, efficient, and consistent search is critical when implementing a solution based on RAG.\n",
    "\n",
    "There are four types of search\n",
    "\n",
    "## [The Role of Search](https://github.com/microsoft/rag-openai/blob/main/topics/RAG_EnablingSearch.md#the-role-of-search)\n",
    "\n",
    "The main purpose of the search tool is to bring the first cut of relevant documents for further analysis by the large language model - it is there to filter the noise and reduce the result set for the model to summarize.\n",
    "\n",
    "Search is at the heart of a RAG solution - it is the mechanism that ensures that the context that is sent to the prompt contains relevant information for it to answer the question.\n",
    "\n",
    "## [Evaluating the Retrieval Component](https://github.com/microsoft/rag-openai/blob/main/topics/RAG_EnablingEvaluation.md#evaluating-the-retrieval-component)\n",
    "\n",
    "Regarding the Retrieval component, the dataset is composed of question and citation instead of question and answer.\n",
    "\n",
    "- question: the user question\n",
    "- citation: the piece(s) of text that contains the relevant content to answer the user question\n",
    "- answer: the final answer in a human readable/friendly format\n",
    "  E\n",
    "  valuating the Retrieval component means to evaluate if for a given query (user question) the search engine is returning the relevant citation(s).\n",
    "\n",
    "Retrieval information is a well-known problem and the classic metrics are: Precision, Recall, F1 Score, Mean Average Precision (MAP), Mean Normalized Discounted Cumulative Gain (Mean NDCG) and Mean Reciprocal Rank (MRR). More details can be found at Evaluating Information Retrieval Models: A Comprehensive Guide to Performance Metrics.\n",
    "\n",
    "[Evaluation Metrics](https://github.com/microsoft/rag-openai/blob/main/topics/RAG_EnablingEvaluation.md#evaluation-metrics)\n",
    "Linnk: https://medium.com/@prateekgaurav/evaluating-information-retrieval-models-a-comprehensive-guide-to-performance-metrics-78aadacb73b4#:~:text=Evaluating%20Information%20Retrieval%20Models%3A%20A%20Comprehensive%20Guide%20to,...%206%206.%20Mean%20Reciprocal%20Rank%20%28MRR%29%20\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Perform a hybrid search\n",
    "\n",
    "Hybrid Retrieval brings out the best of Keyword and Vector Search\n",
    "\n",
    "Keyword and vector retrieval tackle search from different perspectives, which yield complementary capabilities. Vector retrieval semantically matches queries to passages with similar meanings. This is powerful because embeddings are less sensitive to misspellings, synonyms, and phrasing differences and can even work in cross lingual scenarios. Keyword search is useful because it prioritizes matching specific, important words that might be diluted in an embedding.\n",
    "\n",
    "User search can take many forms. Hybrid retrieval consistently brings out the best from both retrieval methods across query types. With the most effective L1, the L2 ranking step can significantly improve the quality of results in the top positions.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# %run 2.rag-implementation-2.ipynb"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Pure Vector Search\n",
    "query = \"scalable storage solution\"\n",
    "query_embeddings = model.encode(query, normalize_embeddings=True)\n",
    "vector_query = VectorizedQuery(\n",
    "    vector=query_embeddings.tolist(), k_nearest_neighbors=3, fields=\"contentVector\"\n",
    ")\n",
    "\n",
    "results = search_client.search(\n",
    "    search_text=query,\n",
    "    vector_queries=[vector_query],\n",
    "    select=[\"title\", \"content\", \"category\"],\n",
    "    top=3,\n",
    ")\n",
    "\n",
    "print_results(results)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Perform a hybrid search\n",
    "\n",
    "Hybrid Retrieval brings out the best of Keyword and Vector Search\n",
    "\n",
    "Keyword and vector retrieval tackle search from different perspectives, which yield complementary capabilities. Vector retrieval semantically matches queries to passages with similar meanings. This is powerful because embeddings are less sensitive to misspellings, synonyms, and phrasing differences and can even work in cross lingual scenarios. Keyword search is useful because it prioritizes matching specific, important words that might be diluted in an embedding.\n",
    "\n",
    "User search can take many forms. Hybrid retrieval consistently brings out the best from both retrieval methods across query types. With the most effective L1, the L2 ranking step can significantly improve the quality of results in the top positions.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Perform a semantic hybrid search - Required Semantic Ranker enabled\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'model' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[4], line 3\u001b[0m\n\u001b[0;32m      1\u001b[0m query \u001b[38;5;241m=\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mwhat is azure sarch?\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m----> 3\u001b[0m query_embeddings \u001b[38;5;241m=\u001b[39m \u001b[43mmodel\u001b[49m\u001b[38;5;241m.\u001b[39mencode(query, normalize_embeddings\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m)\n\u001b[0;32m      4\u001b[0m vector_query \u001b[38;5;241m=\u001b[39m VectorizedQuery(\n\u001b[0;32m      5\u001b[0m     vector\u001b[38;5;241m=\u001b[39mquery_embeddings\u001b[38;5;241m.\u001b[39mtolist(), k_nearest_neighbors\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m3\u001b[39m, fields\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mcontentVector\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m      6\u001b[0m )\n\u001b[0;32m      8\u001b[0m results \u001b[38;5;241m=\u001b[39m search_client\u001b[38;5;241m.\u001b[39msearch(\n\u001b[0;32m      9\u001b[0m     search_text\u001b[38;5;241m=\u001b[39mquery,\n\u001b[0;32m     10\u001b[0m     vector_queries\u001b[38;5;241m=\u001b[39m[vector_query],\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m     16\u001b[0m     top\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m3\u001b[39m,\n\u001b[0;32m     17\u001b[0m )\n",
      "\u001b[1;31mNameError\u001b[0m: name 'model' is not defined"
     ]
    }
   ],
   "source": [
    "%%capture --no-display\n",
    "\n",
    "query = \"what is azure sarch?\"\n",
    "\n",
    "query_embeddings = model.encode(query, normalize_embeddings=True)\n",
    "vector_query = VectorizedQuery(\n",
    "    vector=query_embeddings.tolist(), k_nearest_neighbors=3, fields=\"contentVector\"\n",
    ")\n",
    "\n",
    "results = search_client.search(\n",
    "    search_text=query,\n",
    "    vector_queries=[vector_query],\n",
    "    select=[\"title\", \"content\", \"category\"],\n",
    "    query_type=QueryType.SEMANTIC,\n",
    "    semantic_configuration_name=\"my-semantic-config\",\n",
    "    query_caption=QueryCaptionType.EXTRACTIVE,\n",
    "    query_answer=QueryAnswerType.EXTRACTIVE,\n",
    "    top=3,\n",
    ")\n",
    "\n",
    "semantic_answers = results.get_answers()\n",
    "for answer in semantic_answers:\n",
    "    if answer.highlights:\n",
    "        print(f\"Semantic Answer: {answer.highlights}\")\n",
    "    else:\n",
    "        print(f\"Semantic Answer: {answer.text}\")\n",
    "    print(f\"Semantic Answer Score: {answer.score}\\n\")\n",
    "\n",
    "for result in results:\n",
    "    print(f\"Title: {result['title']}\")\n",
    "    print(f\"Reranker Score: {result['@search.reranker_score']}\")\n",
    "    print(f\"Content: {result['content']}\")\n",
    "    print(f\"Category: {result['category']}\")\n",
    "\n",
    "    captions = result[\"@search.captions\"]\n",
    "    if captions:\n",
    "        caption = captions[0]\n",
    "        if caption.highlights:\n",
    "            print(f\"Caption: {caption.highlights}\\n\")\n",
    "        else:\n",
    "            print(f\"Caption: {caption.text}\\n\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
